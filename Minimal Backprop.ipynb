{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST\n",
    "$h_1=0$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def relu(z, deriv=False):\n",
    "    activations = []\n",
    "    shape = z.shape\n",
    "    z = z.flatten()\n",
    "    if deriv:\n",
    "        for i in range(len(z)):\n",
    "            if z[i] >= 0:\n",
    "                activations.append(1)\n",
    "            else:\n",
    "                activations.append(-0.2)\n",
    "        return np.array(activations).reshape(shape)\n",
    "    for i in range(len(z)):\n",
    "        if z[i] > 0:\n",
    "            activations.append(z[i])\n",
    "        else:\n",
    "            activations.append(-0.2 * z[i])\n",
    "    return np.array(activations).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.47236408  0.35098556 -0.16282832]\n",
      " [ 1.4175084  -2.35780217  0.45368306]]\n",
      "[[ 0.05750707 -0.39551893  0.43416338]\n",
      " [-0.42886034 -0.38810165  1.05099684]\n",
      " [ 0.38446359 -0.76753419 -0.4143932 ]]\n",
      "[[-1.15432547  0.72548309]\n",
      " [ 0.9092547  -0.82310184]\n",
      " [-0.3468875   0.3337282 ]]\n",
      "[[-1.1574449 ]\n",
      " [-0.91594885]]\n"
     ]
    }
   ],
   "source": [
    "def reset():\n",
    "    global w, b\n",
    "    w = [\n",
    "        np.array(np.random.randn(6)).reshape(2,3),\n",
    "        np.array(np.random.randn(9)).reshape(3,3),\n",
    "        np.array(np.random.randn(6)).reshape(3,2),\n",
    "        np.array(np.random.randn(2)).reshape(2,1)\n",
    "    ]\n",
    "    b = [\n",
    "        np.array(np.zeros(3)),\n",
    "        np.array(np.zeros(3)),\n",
    "        np.array(np.zeros(2)),\n",
    "        np.array(np.zeros(1))\n",
    "    ]\n",
    "\n",
    "# [previous, neuron_count]\n",
    "w = [\n",
    "\n",
    "]\n",
    "b = [\n",
    "\n",
    "]\n",
    "\n",
    "reset()\n",
    "\n",
    "for i in w: print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54105797, 0.41605256, 0.01360361]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[0,1]]) @ w[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = [\n",
    "    \n",
    "]\n",
    "a = [\n",
    "    \n",
    "]\n",
    "\n",
    "reset()\n",
    "\n",
    "def forward_prop(X):\n",
    "    h = X\n",
    "    global a, z\n",
    "    a,z  = [], []\n",
    "    for i in range(len(w)):\n",
    "        h = h @ w[i] # weigt * input\n",
    "        h = h + b[i] # bias add\n",
    "        z.append(h)\n",
    "        h = relu(h) # Activation Function\n",
    "        a.append(h)\n",
    "    return h\n",
    "\n",
    "forward_prop(np.array([0,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Prop\n",
    "\n",
    "for each layer\n",
    "\n",
    "$g = loss'(X,y)$\n",
    "\n",
    "## Step 1 ($a$ to $z$)\n",
    "\n",
    "$g = relu'(z)$\n",
    "\n",
    "\n",
    "\n",
    "## Step 2 ($z$ to $W$)\n",
    "\n",
    "$g = relu'(z) * a_{L-1}$\n",
    "\n",
    "# Dimensions\n",
    "\n",
    "$g = [1\\times2]$\n",
    "\n",
    "## Step 1 Activation Function Derriv\n",
    "\n",
    "$g = [1\\times2]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00033035]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.4996697])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.2\n",
    "\n",
    "reset()\n",
    "\n",
    "def back_prop(X, y, print_loss=False):\n",
    "    loss = 0\n",
    "    global a, z, w, b\n",
    "    \n",
    "    g = (X - y).reshape(1,-1).T\n",
    "    loss = 0.5*(y - X)**2\n",
    "    \n",
    "    if print_loss:\n",
    "        print(\"Loss: \", (y - X)**2)\n",
    "    \n",
    "    n_weights, n_bias = [], []\n",
    "    \n",
    "    for x in range(len(w)):\n",
    "        i = len(b) - 1 - x\n",
    "\n",
    "        # Activation Function Derrivative [1xn]\n",
    "        g = g * relu(z[i], True)  # Activation Function Derriv\n",
    "        \n",
    "        # Derivative with respect to weight [1xn]  \n",
    "        if i-1 < 0: w_der = y.reshape(1,-1).T\n",
    "        else: w_der = a[i-1].reshape(1,-1).T  # Previous Layer Activation\n",
    "        \n",
    "        \n",
    "#         print(w_der.shape, g.shape)\n",
    "#         print((w_der @ g).shape)\n",
    "        \n",
    "        # Change in Weights\n",
    "        new_weights = w[i] - learning_rate * (w_der @ g)\n",
    "        n_weights.append(new_weights)\n",
    "        \n",
    "        new_bias = b[i] - learning_rate * g\n",
    "        n_bias.append(new_bias)\n",
    "        \n",
    "        g = g @ w[i].T \n",
    "    \n",
    "    n_weights = list(reversed(n_weights))\n",
    "    n_bias = list(reversed(n_bias))\n",
    "    w = n_weights\n",
    "    b = n_bias\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "X = forward_prop(np.array([0,1]))\n",
    "print(X)\n",
    "back_prop(X, np.array([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  [0.40042846]\n",
      "Loss:  [0.05717091]\n",
      "Loss:  [0.03874792]\n",
      "Loss:  [0.0339624]\n",
      "Loss:  [0.0261027]\n",
      "Loss:  [0.02398881]\n",
      "Loss:  [0.02112197]\n",
      "Loss:  [0.01880983]\n",
      "Loss:  [0.01694079]\n",
      "Loss:  [0.01456519]\n",
      "Loss:  [0.01265015]\n",
      "Loss:  [0.01115511]\n",
      "Loss:  [0.01203928]\n",
      "Loss:  [0.01059292]\n",
      "Loss:  [0.00971486]\n",
      "Loss:  [0.0081658]\n",
      "Loss:  [0.00705318]\n",
      "Loss:  [0.00686392]\n",
      "Loss:  [0.00611966]\n",
      "Loss:  [0.00571631]\n",
      "[[0.55467714]]\n",
      "[[0.99950418]]\n",
      "[[1.1567219]]\n",
      "[[1.94013978]]\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "def train(epochs, size=100):\n",
    "    for i in range(epochs):\n",
    "        tmp = 0.0\n",
    "        for x in range(size):\n",
    "            y1 = randint(0,1)\n",
    "            y2 = randint(0,1)\n",
    "            tmp += back_prop(forward_prop(np.array([y1,y2])), np.array([y1+y2]))[0]\n",
    "        print(\"Loss: \", tmp/size)\n",
    "\n",
    "reset()\n",
    "train(20, 500)\n",
    "print(forward_prop(np.array([0.2,0.3])))\n",
    "print(forward_prop(np.array([0.7,0.2])))\n",
    "print(forward_prop(np.array([1,0])))\n",
    "print(forward_prop(np.array([1,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  [0.15050137]\n",
      "Loss:  [0.12941549]\n",
      "Loss:  [0.13089094]\n",
      "Loss:  [0.12896175]\n",
      "Loss:  [0.12088918]\n",
      "Loss:  [0.12174382]\n",
      "Loss:  [0.11548262]\n",
      "Loss:  [0.10326216]\n",
      "Loss:  [0.07147332]\n",
      "Loss:  [0.03182517]\n",
      "Loss:  [0.0037258]\n",
      "Loss:  [0.00085587]\n",
      "Loss:  [0.00044528]\n",
      "Loss:  [0.00031997]\n",
      "Loss:  [0.00018049]\n",
      "Loss:  [0.00017935]\n",
      "Loss:  [0.00011844]\n",
      "Loss:  [9.35320416e-05]\n",
      "Loss:  [5.53553604e-05]\n",
      "Loss:  [3.18098264e-05]\n",
      "[[0.99960762]]\n",
      "[[1.00028389]]\n",
      "[[0.0150068]]\n",
      "[[7.92150614e-05]]\n",
      "[array([[ 1.97054459, -2.81806191,  0.03650922],\n",
      "       [ 0.29425528, -0.92453928,  0.92799386]]), array([[ 0.20280271,  0.41829016, -0.62599738],\n",
      "       [ 1.84691646,  0.68244146, -0.96449574],\n",
      "       [ 1.02034973,  0.52363776,  0.89989944]]), array([[-0.10206539, -2.20438863],\n",
      "       [ 0.91434694,  1.10866309],\n",
      "       [-0.31747786,  0.99122434]]), array([[ 0.85650762],\n",
      "       [-2.5608622 ]])]\n",
      "[array([[-0.60133739, -0.00860175,  0.01973175]]), array([[-1.37919203, -0.06200702,  0.05902828]]), array([[-0.84098286,  0.5866321 ]]), array([[-0.22358465]])]\n"
     ]
    }
   ],
   "source": [
    "X = [\n",
    "    [0,1],\n",
    "    [0,0],\n",
    "    [1,0],\n",
    "    [1,1]\n",
    "]\n",
    "\n",
    "y = [1,0,1,0]\n",
    "\n",
    "reset()\n",
    "\n",
    "def train(epochs, size=100):\n",
    "    for i in range(epochs):\n",
    "        tmp = 0.0\n",
    "        for x in range(size):\n",
    "            y1 = randint(0,3)\n",
    "            tmp += back_prop(forward_prop(np.array(X[y1])), np.array(y[y1]))[0]\n",
    "        print(\"Loss: \", tmp/size)\n",
    "      \n",
    "\n",
    "train(20, 100)\n",
    "\n",
    "print(forward_prop(np.array([1,0])))\n",
    "print(forward_prop(np.array([0,1])))\n",
    "print(forward_prop(np.array([0,0])))\n",
    "print(forward_prop(np.array([1,1])))\n",
    "\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w': [array([[ 1.54876358, -1.24253546, -0.41267138],\n",
      "       [ 1.05036975, -0.91747989,  1.00974905]]), array([[-1.2548782 , -1.40340579, -0.88367188],\n",
      "       [ 0.20918457,  0.32485332, -1.09196149],\n",
      "       [-0.62706676, -1.475977  ,  1.54952924]]), array([[-0.94844447, -0.63866621],\n",
      "       [-1.28160641, -2.10228276],\n",
      "       [ 0.16416751,  1.29274642]]), array([[ 0.67945281],\n",
      "       [-2.88925098]])], 'b': [array([[-0.05793085,  0.34370978,  0.38956388]]), array([[ 0.05749785,  1.28978517, -0.29233234]]), array([[-0.12134365,  1.65705825]]), array([[-0.37683778]])]}\n"
     ]
    }
   ],
   "source": [
    "working_w_b = {\n",
    "    \"w\": w,\n",
    "    \"b\": b\n",
    "}\n",
    "\n",
    "print(working_w_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "[[1.]]\n",
      "[[5.77118852e-16]]\n",
      "[[7.68392101e-16]]\n",
      "[array([[ 0.82497381,  0.59840391,  1.31815359],\n",
      "       [-0.22509377,  1.19228404,  2.24951462]]), array([[ 0.33853337, -0.48228155, -1.63981744],\n",
      "       [ 0.78615243, -0.48763467,  0.3400973 ],\n",
      "       [ 0.93141037, -1.35151089,  0.62963734]]), array([[ 5.07610397e-01, -3.67255683e-01],\n",
      "       [-1.36799822e-03, -4.70333681e-01],\n",
      "       [-1.37615029e+00,  9.68110094e-01]]), array([[0.81541792],\n",
      "       [0.96582707]])]\n",
      "[array([[0.22509377, 0.10685884, 0.19480117]]), array([[0.01200832, 0.        , 0.37186151]]), array([[ 0.04306578, -0.02670464]]), array([[3.2272429e-16]])]\n"
     ]
    }
   ],
   "source": [
    "w = working_w_b[\"w\"]\n",
    "b = working_w_b[\"b\"]\n",
    "\n",
    "print(forward_prop(np.array([1,0])))\n",
    "print(forward_prop(np.array([0,1])))\n",
    "print(forward_prop(np.array([0,0])))\n",
    "print(forward_prop(np.array([1,1])))\n",
    "\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "name": "Minimal Backprop.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
