{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z, deriv=False):\n",
    "    activations = []\n",
    "    shape = z.shape\n",
    "    z = z.flatten()\n",
    "    if deriv:  # Return Derivative of Function\n",
    "        \n",
    "        for i in range(len(z)):  # Element Wise\n",
    "            if z[i] >= 0:\n",
    "                activations.append(1)\n",
    "            else:\n",
    "                activations.append(0.2)\n",
    "                \n",
    "        return np.array(activations).reshape(shape)\n",
    "    \n",
    "    for i in range(len(z)):\n",
    "        if z[i] > 0:\n",
    "            activations.append(z[i])\n",
    "        else:\n",
    "            activations.append(0.2 * z[i])\n",
    "            \n",
    "    return np.array(activations).reshape(shape)\n",
    "\n",
    "input = [1.,0.,-5.]\n",
    "print('LeakyReLU: ', input, ' -> ', list(relu(np.array(input))))\n",
    "\n",
    "print('LeakyReLU (deriv): ', input, ' -> ', list(relu(np.array(input), True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(3, 3)\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "def add_layer(weight, bias, size, input_dim=None):\n",
    "    if not input_dim:\n",
    "        input_dim = weight[-1].shape[0]\n",
    "    weight.append(1 * np.random.uniform(-1, 1, (size, input_dim)))\n",
    "    bias.append(np.zeros(size))\n",
    "    print(weight[-1].shape)\n",
    "\n",
    "w, b = [], []\n",
    "add_layer(w, b, 3, 2)\n",
    "add_layer(w, b, 3)\n",
    "add_layer(w, b, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h:  [[0 1]\n",
      " [0 4]\n",
      " [1 3]\n",
      " [5 4]] (4, 2)\n",
      "Layer 0 | (2, 3) dot (4, 2)\n",
      "Layer 1 | (3, 3) dot (4, 3)\n",
      "Layer 2 | (3, 1) dot (4, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.30424509],\n",
       "       [1.21698037],\n",
       "       [0.5180534 ],\n",
       "       [0.10904002]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, z = [], []  # Global Variables\n",
    "\n",
    "\n",
    "def forward_prop(X, do_print=False):\n",
    "    h = X\n",
    "    if do_print: print('h: ', h, h.shape)\n",
    "    global a, z\n",
    "    a,z  = [], []\n",
    "    for i in range(len(w)):\n",
    "        if do_print: print(f'Layer {i} | {w[i].T.shape} dot {h.shape}')\n",
    "        h = h @ w[i].T  # weigt * input\n",
    "        h = h + b[i] # bias add\n",
    "        z.append(h)\n",
    "        h = relu(h) # Activation Function\n",
    "        a.append(h)\n",
    "    return h\n",
    "\n",
    "forward_prop(np.array([\n",
    "    [0,1], \n",
    "    [0, 4], \n",
    "    [1, 3], \n",
    "    [5, 4]]), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "(3, 2)\n",
      "(3, 3)\n",
      "(1, 3)\n",
      "[Epoch 0] Loss: 0.20002296198569222\n",
      "[Epoch 1] Loss: 0.1285353643227414\n",
      "[Epoch 2] Loss: 0.11614952876341414\n",
      "[Epoch 3] Loss: 0.11140891813685874\n",
      "[Epoch 4] Loss: 0.10766448533234615\n",
      "[Epoch 5] Loss: 0.10466218445739747\n",
      "[Epoch 6] Loss: 0.10264927858294384\n",
      "[Epoch 7] Loss: 0.10092676447068935\n",
      "[Epoch 8] Loss: 0.09921366138463471\n",
      "[Epoch 9] Loss: 0.09769475394163422\n",
      "[Epoch 10] Loss: 0.09614067202375312\n",
      "[Epoch 11] Loss: 0.09465823171833829\n",
      "[Epoch 12] Loss: 0.09323496445249799\n",
      "[Epoch 13] Loss: 0.09185980533248343\n",
      "[Epoch 14] Loss: 0.09036340935365184\n",
      "[Epoch 15] Loss: 0.08889370037921625\n",
      "[Epoch 16] Loss: 0.08727222588977107\n",
      "[Epoch 17] Loss: 0.08570643169721723\n",
      "[Epoch 18] Loss: 0.08429399736255701\n",
      "[Epoch 19] Loss: 0.0828135993212475\n",
      "[Epoch 20] Loss: 0.08126145748260857\n",
      "[Epoch 21] Loss: 0.07956812401392374\n",
      "[Epoch 22] Loss: 0.0776859782743706\n",
      "[Epoch 23] Loss: 0.06805484453054836\n",
      "[Epoch 24] Loss: 0.05271964694281026\n",
      "[Epoch 25] Loss: 0.03675888576949414\n",
      "[Epoch 26] Loss: 0.023629680936185508\n",
      "[Epoch 27] Loss: 0.014255775043121177\n",
      "[Epoch 28] Loss: 0.008525272603519905\n",
      "[Epoch 29] Loss: 0.005197636752344618\n",
      "[Epoch 30] Loss: 0.0032880219633662456\n",
      "[Epoch 31] Loss: 0.0022158545049105896\n",
      "[Epoch 32] Loss: 0.0015029392913810178\n",
      "[Epoch 33] Loss: 0.0010167095181158156\n",
      "[Epoch 34] Loss: 0.0006918307615995463\n",
      "[Epoch 35] Loss: 0.0004803250788491729\n",
      "[Epoch 36] Loss: 0.00033360320914605277\n",
      "[Epoch 37] Loss: 0.00023555324209662267\n",
      "[Epoch 38] Loss: 0.00017006510171831685\n",
      "[Epoch 39] Loss: 0.00012682687672190522\n",
      "[Epoch 40] Loss: 9.736566733192957e-05\n",
      "[[ 0.997]\n",
      " [ 0.998]\n",
      " [ 0.021]\n",
      " [-0.015]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "\n",
    "X = np.array([[1,0], \n",
    "              [0,1], \n",
    "              [1,1], \n",
    "              [0,0]])\n",
    "print(X.shape)\n",
    "y = np.array([[1], [1], [0], [0]])\n",
    "\n",
    "learning_rate = 0.3\n",
    "\n",
    "def loss(pred, y, deriv=False):\n",
    "    return 0.5* 1/len(y) * np.sum((pred - y)**2)\n",
    "    \n",
    "def backprop_entry(X, label, print_loss=False):\n",
    "    global a, z, w, b, n_weights, n_bias, learning_rate\n",
    "    n_weights, n_bias = [], []\n",
    "    y = forward_prop(X)\n",
    "#     print(y.T, label.T)\n",
    "    backprop_rec(0, X, y, label)\n",
    "    \n",
    "    # Update Weights\n",
    "    w = list(reversed(n_weights))\n",
    "    b = list(reversed(n_bias))\n",
    "    if print_loss:\n",
    "        loss(y, label)\n",
    "    return loss(y, label)  # Return Loss\n",
    "\n",
    "\n",
    "def backprop_rec(i, X, y, label):\n",
    "    global a, z, w, b, n_weights, n_bias\n",
    "    # Base Case\n",
    "    if i+1 > len(w): \n",
    "        return (y - label)\n",
    "    g = backprop_rec(i+1, X, y, label) * relu(z[i], True)  # Get Next Layer Derivative\n",
    "#     print(\"Jacobi\", g.shape)\n",
    "    # Derivative with respect to weight [1xn]  \n",
    "    if i-1 < 0: w_der = X  # Input Matrix\n",
    "    else: w_der = a[i-1]  # Previous Layer Activation\n",
    "\n",
    "    # Save change in weights\n",
    "#     print(\"Weight Deriv:\", w_der.shape, (w_der.T @ g).shape)\n",
    "    n_weights.append(w[i] - learning_rate * 1/len(X) * (w_der.T @ g).T)\n",
    "    n_bias.append(b[i] - learning_rate * 1/len(X) * np.mean(g, axis=0))\n",
    "    \n",
    "#     print('new weight',np.mean(g,axis=0).shape, b[i].shape)\n",
    "    \n",
    "    return g @ w[i]\n",
    "\n",
    "def train_rec(epochs, size=100, threshold=0.0001, print_interval=1):\n",
    "    l = []\n",
    "    for i in range(epochs):\n",
    "        sum_loss = 0.0\n",
    "        for x in range(size):\n",
    "            sum_loss += backprop_entry(X, y)\n",
    "        l.append(sum_loss/size)\n",
    "        if not i % print_interval: print(f'[Epoch {i}] Loss: {l[-1]}')\n",
    "        if l[-1] < threshold or l[-1] != l[-1]: break\n",
    "    return np.array(l).flatten()\n",
    "\n",
    "# Reinitialize Wei\n",
    "w, b = [], []\n",
    "add_layer(w, b, 3, 2)\n",
    "add_layer(w, b, 3)\n",
    "add_layer(w, b, 1)\n",
    "\n",
    "loss_over_time = train_rec(100,10)\n",
    "\n",
    "print(forward_prop(np.array([[1,0], \n",
    "                             [0,1], \n",
    "                             [1,1], \n",
    "                             [0,0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "(3, 3)\n",
      "(3, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[6.4, 3.2, 4.5, 1.5],\n",
       "        [6.8, 3.2, 5.9, 2.3]]), array([[0., 1., 0.],\n",
       "        [0., 0., 1.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('./data/iris.data', header=None)\n",
    "\n",
    "data = pd.concat([data,pd.get_dummies(data.iloc()[:,4])],axis=1)\n",
    "data = data.drop(data.columns[4], axis=1)\n",
    "\n",
    "w, b = [], []\n",
    "add_layer(w, b, 3, 4)\n",
    "add_layer(w, b, 3)\n",
    "add_layer(w, b, 3)\n",
    "\n",
    "def get_batch(size):\n",
    "    d = data.sample(size, replace=True).to_numpy()\n",
    "    return d[:,:4], d[:, 4:]\n",
    "get_batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "(6, 3)\n",
      "(6, 6)\n",
      "(6, 6)\n",
      "(3, 6)\n",
      "[Epoch 0] Loss: 1.9639126526460076\n",
      "[Epoch 100] Loss: 0.7451599861500217\n",
      "[Epoch 200] Loss: 0.683965629531997\n",
      "[Epoch 300] Loss: 0.7016441886771566\n",
      "[Epoch 400] Loss: 0.4354250181102146\n",
      "[Epoch 500] Loss: 0.41492213897076613\n",
      "[Epoch 600] Loss: 0.4008219685485013\n",
      "[Epoch 700] Loss: 0.3956987193057733\n",
      "[Epoch 800] Loss: 0.3808141067733698\n",
      "[Epoch 900] Loss: 0.373312488440401\n",
      "Prediction: 0 (1) [0.14432013647672512]\n",
      "Prediction: 0 (1) [0.1482015576594029]\n",
      "Prediction: 0 (1) [0.14502052912289254]\n",
      "Prediction: 0 (1) [0.1428939297624538]\n",
      "Prediction: 0 (1) [0.14755022956293187]\n",
      "Prediction: 0 (1) [0.14238492457966684]\n",
      "Prediction: 0 (0) [0.09527308444197449]\n",
      "Prediction: 0 (1) [0.14755022956293187]\n",
      "Prediction: 0 (0) [0.09107808188405205]\n",
      "Prediction: 0 (0) [0.09879624048112991]\n",
      "Prediction: 0 (0) [0.10310064124509373]\n",
      "Prediction: 0 (2) [0.12049214567281144]\n",
      "Prediction: 0 (2) [0.1195969859252416]\n",
      "Prediction: 0 (2) [0.11926582008620626]\n",
      "Prediction: 0 (2) [0.12162173077665002]\n",
      "Prediction: 0 (2) [0.11817823016142792]\n",
      "Prediction: 0 (2) [0.11919729847290553]\n",
      "Prediction: 0 (2) [0.12162173077665002]\n",
      "Prediction: 0 (0) [0.09729232399741783]\n",
      "Prediction: 0 (0) [0.09525326393070449]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "\n",
    "\n",
    "learning_rate = 0.2\n",
    "\n",
    "# Reinitialize Wei\n",
    "w, b = [], []\n",
    "add_layer(w, b, 3, input_dim=4)\n",
    "add_layer(w, b, 6)\n",
    "add_layer(w, b, 6)\n",
    "add_layer(w, b, 6)\n",
    "add_layer(w, b, 3)\n",
    "\n",
    "def train_iris(epochs, size=100, threshold=0.0001, print_interval=1):\n",
    "    l = []\n",
    "    for i in range(epochs):\n",
    "        sum_loss = 0.0\n",
    "        X, y = get_batch(size)\n",
    "        \n",
    "        \n",
    "        if not i % print_interval: print(f'[Epoch {i}] Loss: {backprop_entry(X, y)}')\n",
    "#         if l[-1] < threshold or l[-1] != l[-1]: break\n",
    "    return np.array(l).flatten()\n",
    "\n",
    "loss_over_time = train_iris(1000, 1500, print_interval=100)\n",
    "eval_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 0 (0) [0.001405609412778772]\n",
      "Prediction: 2 (2) [0.07033369361992152]\n",
      "Prediction: 0 (0) [0.0008782069765449825]\n",
      "Prediction: 0 (0) [0.0006072314585636652]\n",
      "Prediction: 0 (0) [0.007384173868787134]\n",
      "Prediction: 0 (0) [0.002203145123753915]\n",
      "Prediction: 2 (2) [0.07082063326090632]\n",
      "Prediction: 2 (1) [0.0932930517372528]\n",
      "Prediction: 2 (2) [0.07061437789629602]\n",
      "Prediction: 2 (1) [0.0940222465868569]\n",
      "Prediction: 0 (0) [0.0008950220999844055]\n",
      "Prediction: 2 (2) [0.06930771429030433]\n",
      "Prediction: 2 (1) [0.09300236441891647]\n",
      "Prediction: 0 (0) [0.00033716663512219905]\n",
      "Prediction: 2 (2) [0.07221230360530786]\n",
      "Prediction: 0 (0) [0.0017255614460869734]\n",
      "Prediction: 2 (2) [0.07033369361992152]\n",
      "Prediction: 2 (2) [0.07265265188904353]\n",
      "Prediction: 0 (0) [0.003149062867059336]\n",
      "Prediction: 2 (2) [0.07217626860218396]\n"
     ]
    }
   ],
   "source": [
    "def eval_iris():\n",
    "    X, y = get_batch(20)\n",
    "    pred = forward_prop(X)\n",
    "    for p, label in zip(pred, y):\n",
    "        print(f'Prediction: {np.argmax(p)} ({np.argmax(label)}) [{loss(p, label)}]')\n",
    "eval_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(np.array([[0,0,1]]), np.array([1,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in b:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
