#+bind: org-export-publishing-directory "./exports"
#+TITLE: Backpropagation
#+LANGUAGE: de
#+EXPORT_FILE_NAME: docs/index.html
#+AUTHOR: Lucas Sas Brunschier
#+DATE: SS20
#+EMAIL: lucassas@live.de
#+OPTIONS: toc:nil num:nil timestamp:nil
#+REVEAL_EXTRA_CSS: style.css
#+STYLE: <link rel="stylesheet" type="text/css" href="style.css" />
#+REVEAL_ROOT: reveal
#+REVEAL_THEME: solarized

* Intro
Präsentation ist auch online [[https://sirbubbls.github.io/backpropagation-seminar][sirbubbls.github.io/backpropagation-seminar]]

Präsentation ist in Org-Mode geschrieben, also sourcen aller Grafiken und
Beispiele sind integriert.
** Zusätzliche Ressourcen
Deep Learning (Ian Goodfellow, Yoshua Bengio & Aaron Courville)
#+ATTR_ORG: :width 200
#+ATTR_HTML: :width 150
[[https://images-eu.ssl-images-amazon.com/images/I/610HnULa0dL._SY445_QL70_ML2_.jpg]]

https://www.deeplearningbook.org

[[https://www.deeplearningbook.org/contents/mlp.html][Back-propagation Kapitel]]

** Jupyter Notebook
Beispiele für alle Methoden dieser Präsentation sind in diesem [[https://github.com/SirBubbls/backpropagation-seminar/blob/master/Backpropagation.ipynb][IPython Notebook]] zu finden.
* Agenda
1. Vorwissen
   - Gradients & Stochastic Gradient Descent
   - Computational Graphs
2. Neuronale Netze
3. Forward Propagation
4. Back-propagation
   - Kettenregel
   - Back-propagation
   - Delta Rule
   - Implementation in Python
5. General Back-propagation

* Vorwissen
** Gradient
Der Gradient ist der Vektor aller partiellen Ableitungen einer Funktion $f$.
#+begin_quote
Notation: $\nabla_xf(x)$
#+end_quote
*** Beispiel
#+begin_quote
$f(x) = 2x_1^2 + x_2^3$
#+end_quote
$\rightarrow \nabla_xf(x)=\left(\begin{array}{c} f'_{x_1} \\ f'_{x_2} \end{array}\right)= \left(\begin{array}{c} 4x_1 \\ 3x^2_2 \end{array}\right)$
** Stochastic Gradient Descent
Der Gradient Descent Algorithmus wird dafür verwendet ein lokales Minimum einer Funktion zu bestimmen.
*** Beispiel
Funktion $f(x)=x_1^2-x_2^2$ ist gegeben. \\
Also: $\nabla_xf(x)=\left(\begin{array}{c} f'_{x_1} \\ f'_{x_2} \end{array}\right)= \left(\begin{array}{c} 2x_1 \\ -2x_2 \end{array}\right)$ \\
Wir starten mit einem beliebigen Punkt: z.B. $\left(\begin{array}{c} 2 \\ 1 \end{array}\right)$ und setzen ein: \\
$\left(\begin{array}{c} 2x_1 \\ -2x_2 \end{array}\right) = \left(\begin{array}{c} 2 * 2 \\ -2 * 1 \end{array}\right) = \left(\begin{array}{c} 4 \\ -2 \end{array}\right)$

$Neuer\ Punkt = \left(\begin{array}{c} 2 \\ 1 \end{array}\right)+ \lambda \left(\begin{array}{c} 4 \\ -2 \end{array}\right)$ mit $\lambda: learning\ rate$

** Computational Graphs
#+begin_notes
Rechenoperationen in ANN's werden typischerweise nicht in mathematischen Formeln angegeben, sondern in sog. computational Graphs.
#+end_notes

Typischerweise werden Operationen in artificial neural networks nicht mit mathematischen Formeln angegeben, sondern als Graph dargestellt.

*** Repräsentation
Jede Node in einem Graph $G$ repräsentiert eine mathematische Operation oder eine Input Variable.\\

Beispielsweise:
- Matrix Multiplikation
- Addition
- Skalare Multiplikation
*** Addition Beispiel
$$
y = a+b
$$

[[./basic_graph.png]]
*** Komplexere Beispiele
$x=y+z$ \\
$a=x\odot z$

[[./basic_graph_2.jpg]]

* Künstliche Neuronale Netze & Deep Learning
** Künstliche Neuronale Netze
Als Vorbild dienen Neuronale Netze in der Biologie, jedoch sind beide Felder doch unterschiedlicher als man vielleicht erwarten würde.

#+begin_quote
In diesem Vortrag werden nur fully connected feed forward networks behandelt.
#+end_quote

** Formale Definition
Formale Definition für ein neuronales Netz: $y=f(x; \theta)$ und $y=f^*(x)$
- $y$ ist den Wert den unser NN vorraussagen soll
- $x$ sind die Input Daten, die das NN erhält
- $\theta$ sind Parameter des NN's, um $f$ so nah wie möglich an
  die optimale Funktion $f^*$ anzunähern.

** Wie ist nun ein neuronales Netzwerk aufgebaut?
Wir teilen das Netzwerk in Schichten (Layer) auf.

#+ATTR_HTML: :width 50% :height 50%
https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Neural_network.svg/1200px-Neural_network.svg.png

Jeder Layer bildet eine Funktion $f^{i}$, mit $i=Layer\ Index$ ab.

*** Formell
Somit ist ein neurales Netzwerk eine Kette an Funktionen $f$.
#+begin_quote
Ein Netz mit $3$ Layern wäre somit $f^2(f^1(f^0(X)))$
mit $X=Input\ Data$
#+end_quote
*** Aufbau eines Layers
Jeder Layer enthält *mindestens* folgende Informationen:
- Eine Weight Matrix ($w$)
- Einen Bias Vektor ($b$)
- Aktivierungsfunktion ($\sigma$)
*** Aktivierungsfunktion
#+begin_notes
Non linearity Functions werden benötigt, da eine zwei lineare Funktionen
immer zu einer weiteren linearen Funktion reduziert werden können. \\
*Ausnahme* bei einem Output Layer dessen Output eine reelle Zahl sein soll.
#+end_notes

Da wir bei Neural Networks oft versuchen non-lineare Zusammenhänge zu approximieren, benötigen wir auch eine nicht-lineare Komponente in unserem NN.

*** Beliebte Aktivierungsfunktionen
- Rectified Linear Unit ($ReLU$) \\
  #+begin_quote
  $f(x)=max(0, x)$
  #+end_quote
- $Leaky\ ReLU$ \\
  #+begin_quote
  $f(x)=\begin{cases} x &\quad if\ x > 0 \\ 0.1x &\quad else \end{cases}$
#+end_quote
- Sigmoid Function \\
  #+begin_quote
  $f(x)= \frac{1}{1+e^{-t}}$
  #+end_quote
 
*** Function Plot
[[./activation_functions.jpg]]

*** Cost Function ($J$)
Eine Funktion um zu bestimmen wie 'nah' wir uns an unserem erwarteten Inference Wert befinden.
#+begin_quote
In dieser Präsentation benutzen wir die Euklidean-Distance $(x-y)^2$ als Cost Function.
#+end_quote
* Forward Propagation
Ein Layer in einem Feed-Forward Neural Network besteht aus folgenden Elementen:
- Inputs ($X$)
- Weights ($W$)
- Biases ($b$)
- Output ($a$)
** Allgemein
#+begin_notes
Jede Verbindung repräsentiert einen Float. \\
Jedes Neuron enthält einen Vektor mit
#+end_notes

Jedes Neuron eines Layers $L_i$ ist mit allen Neuronen des Layers $L_{i-1}$ verbunden. \\

[[./connections.jpg]]

*** Berechnung des Inputs

Jedes Neuron enthält einen Vektor mit Weights $w$, der Angibt wie stark jeder Input gewichtet wird. \\
$z=a_1*w_1+a_2*w_2$ oder $z=w^Ta$

[[./connections.jpg]]

** Formell
Um die Aktivierungen ($a$) eines Layers zu berechen können wir folgende Formel benutzen:

#+begin_quote
$a_L = \sigma(a_{L-1} w_L + b_L)$
#+end_quote
Der berechnete Vektor $a_L$ dient dem Layer $L+1$ als Input.

** Computational Graph
$$
a = \sigma(a_{L-1}w_L+b)
$$

[[./forward_prop_graph.png]]

** Beispiel (XOR)
$W=\left[\begin{array}{ccc} 1 & 1 \\ 1 & 1 \end{array}\right]$ \\
$b=\left [\begin{array}{ccc} 0 \\ -1 \end{array} \right]$ \\
** Multiplizieren der Weights ($W$) und Inputs ($X$)
$$
XW=\left[\begin{array}{ccc} 0 & 0 \\ 0 & 1 \\ 1 & 0 \\ 1 & 1 \end{array} \right]
\left[\begin{array}{ccc} 1 & 1 \\ 1 & 1 \end{array}\right]=
\left[\begin{array}{ccc} 0 & 0 \\ 1 & 1 \\ 1 & 1 \\ 2 & 2 \end{array} \right]
$$

** Addieren des Bias Vektors ($b$)
$$
XW + b=
\left[\begin{array}{ccc} 0 & 0 \\ 1 & 1 \\ 1 & 1 \\ 2 & 2 \end{array} \right] +
\left(\begin{array}{ccc} 0 \\ -1 \end{array}\right)=
\left[\begin{array}{ccc} 0 & -1 \\ 1 & 0 \\ 1 & 0 \\ 2 & 1 \end{array} \right]
$$
** Aktivierungsfunktion (in diesem Fall $ReLU$)
#+begin_quote
$ReLU:= f(x)=max(0, x)$
#+end_quote
$$
relu(XW+b)=
relu(\left[\begin{array}{ccc} 0 & -1 \\ 1 & 0 \\ 1 & 0 \\ 2 & 1 \end{array} \right])=
\left[\begin{array}{ccc} 0 & 0 \\ 1 & 0 \\ 1 & 0 \\ 2 & 1 \end{array} \right]
$$

Die Aktivierungsfunktion wird auf jedes Element der Matrix ausgeführt.

** Output Layer
Multiplizieren der Output Matrix des ersten Layers mit den Weights des Output Layers ($w$).
$$
w= relu(XW+b)* \left[\begin{array}{ccc} 1 \\ -2 \end{array}\right]=
\left[\begin{array}{ccc} 0 & 0 \\ 1 & 0 \\ 1 & 0 \\ 2 & 1 \end{array} \right]*
\left[\begin{array}{ccc} 1 \\ -2 \end{array}\right]=
\left[\begin{array}{ccc} 0 \\ 1 \\ 1 \\ 0 \end{array}\right]
$$

** Predictions & Input
Input: $\left[\begin{array}{ccc} 0 & 0 \\ 0 & 1 \\ 1 & 0 \\ 1 & 1 \end{array} \right]$ \\
Predictions: $\left[\begin{array}{ccc} 0 \\ 1 \\ 1 \\ 0 \end{array}\right]$

** Code Beispiel
#+BEGIN_SRC python
def forward(X):
    a = X
    for layer in L:
        a = h @ layer.weights + layer.bias
    return a
#+END_SRC

** Laufzeitkomplexität
#+begin_notes
Wir multiplizieren jedes Weight und addieren einen Bias Wert.
#+end_notes

#+begin_quote
$$
O(w)
$$
#+end_quote

- $w$ Anzahl der Weights in neuronalem Netz.

* Backpropagation
** Wozu brauchen wir den Back-propagation Algorithmus?
#+begin_notes
Gesuchte Gradients:
- Ableitung von $J$ in Abhängigkeit von Bias $b^k$
- Ableitung von $J$ in Abhängigkeit von Weights $w^k$
#+end_notes

Ein fundamentaler Baustein, von neuralen Netzen.

Back-propagation ist kein Lernalgorithmus/Optimierungsalgorithmus, sondern aussschlißlich für die Generierung der Gradients jedes Layers zuständig.

Also suchen wir folgende Gradients:
 - $\nabla_{b^k} J$
 - $\nabla_{w^k} J$

** Kettenregel
#+begin_notes
Da ein NN prinzipiell nur viele geschachtelte Funktionen sind ist die Kettenregel sehr nützlich um die Ableitungen für jede Funktion zu bestimmen.
#+end_notes

Die Kettenregel ist nützlich um Ableitungen aus schon bereits vorhandenen Ableitungen zu konstruieren.

$$y=g(x)\ und\ z=f(g(x))=f(y)$$

Dann besagt die Kettenregel: $\frac{dz}{dx} = \frac{dz}{dy} \frac{dy}{dx}$

** Kettenregel als Graph

#+begin_notes
An der Formel $f'(f(f(w)))f'(f(w))f'(w)$ erkennt man, dass immer die Zwischenergebnisse aus jedem Schritt benötigt werden um die korrekte Ableitung $\frac{\partial z}{\partial w}$ zu bestimmen.
#+end_notes

$$
x = f(w),\ y=f(x),\ z=f(y)
$$

[[./chain_rule_derriv.jpg]]

$$
\frac{\partial z}{\partial w}=
\frac{\partial z}{\partial y}
\frac{\partial y}{\partial x}
\frac{\partial x}{\partial w}
=
f'(y)f'(x)f'(w) \\
= f'(f(f(w)))f'(f(w))f'(w)
$$

** Anpassung der Forward Propagation
#+begin_notes
Wie davor gezeigt müssen wir nun Zwischenergebnisse aus der Forward Progagation speichern um im Anschluss effizient die Back-propagation durchführen zu können.
Eine Alternative ist bei *limitiertem Speicher* die Zwischenergebnisse immer neu zu evaluieren, wenn sie benötigt werden. (-> Höhere Laufzeit)
#+end_notes

Wir benötigen folgende Werte aus jedem Layer um den Back-propagation Algorithmus ausführen zu können.
- $a$ Aktivation Vektor
- $z$ Pre Activation Function Vektor
 
#+begin_quote
$f'(y)f'(x)f'(w)$: Speichern der Zwischenergebnisse in Variablen
$f'(f(f(w)))f'(f(w))f'(w)$: Neu Evaluierung der Zwischenergebnisse
#+end_quote
** Beschreibung des Algorithmus
*** Schritt 1
Forward Propagation ausführen.
*** Schritt 2
Wir berechnen den Gradienten der Cost Function $J$.
$J = \frac{1}{2} (y-X)^2 \rightarrow \nabla_y J = X - y$
*** Schritt 3
Erst müssen wir den Gradienten in Relation zu den pre activation function values berechnen.
#+begin_quote
$\nabla_{a^{k}} J = g \odot f'(a^{(k)})$
#+end_quote
mit $f'(x) := Ableitung\ der\ Aktivierungsfunktioin$
*** Schritt 4
Bias Gradienten berechnen.
#+begin_quote
$\nabla_{b^{k}} J = g$
#+end_quote
Weight Gradienten berechnen.
#+begin_quote
$\nabla_{w^k} J = ga^{k-1}$
#+end_quote
*** Schritt 5
$\nabla a^{k-1} J = w^kg$
*** Wiederholen von Schritt 3 - 5 des nächsten Layers ($L{-1}$)
** Graph
#+begin_notes
Wir bilden einen Pfad (von Hinten nach Vorne) an Pfeilen zu einem Gradienten einer Node die wir berechnen wollen.
Wir multiplizieren alle partiellen Ableitungen auf dem Weg dahin miteinander.
#+end_notes

[[./backprop_derriv.jpg]]

** Delta Rule
In neural Networks kann der Back-propagation Algorithmus zu der sog. *Delta Rule* zusammengefasst werden.
#+begin_notes
$\lambda$ ist learning rate \\
$\alpha$ ist die Aktivierungsfunktion \\
$z$ ist inputs * weights \\
#+end_notes

#+begin_quote
$$
\nabla w_{ji} = \lambda ( - a) \alpha'(z)a_{L-1}
$$
#+end_quote

** Praktisches Beispiel in Python
#+BEGIN_EXPORT html
<div class = "stretch">
     <iframe width="100%" height="100%" src="http://localhost:8888/lab"></iframe>
</div>
#+END_EXPORT

** Komplexität
#+begin_quote
*Wichtig* \\
Folgende Komplexitäten beziehen sich ausschließlich auf den Backpropagation Algorithmus.
#+end_quote

*** Laufzeitkomplexität
#+begin_notes
Wir multiplizieren die transponierte Weight Matrix also die gleiche Komplexität wie
Forward-propagation.
#+end_notes

Back-propagation besitzt die gleiche Laufzeitkomplexität wie Forward-propagation.

#+begin_quote
$$
O(w)
$$
#+end_quote

- $w$ Anzahl der Weights in neuronalem Netz.

*** Speicherkomplexität
#+begin_quote
$$
O(mh)
$$
#+end_quote

- $m$ Anzahl an Elementen in Batch
- $h$ Anzahl der Hidden-Units
 
** Anmerkungen
In der Praxis werden keine Vektoren als Input Daten benutzt, sondern Matrizen (siehe ~XOR~ Beispiel).
$$
Input = \left[\begin{array}{ccc} 0 & 0 \\ 0 & 1 \\ 1 & 0 \\ 1 & 1 \end{array} \right]
$$

Wir erhalten nun auch mehrere Gradienten in Form einer Matrix. Wir können nun den Durchschnitt der Gradienten nutzen um unsere Weights anzupassen.

* General Back-propagation
Bisher haben wir uns nur mit Back-propagation in Zusammenhang mit neuronalen Netzwerken beschäftigt. \\
Back-propagation kann aber auch generell für andere Anwendungen eingesetzt werden.

** Symbol to Number / Symbol to Symbol
Es existieren zwei verschiedene Möglichkeiten die Berechnungen der Gradients durchzuführen.

- Symbol to Number
- Symbol to Symbol

*** Symbol to Number
#+begin_notes
Methode die wir in vorherigen Beispielen verwendet waren.
#+end_notes

Die Input Variablen werden durch Zahlenwerte ersetzt und daraufhin (wie besprochen) alle nötigen Gradienten berechnet.

*** Symbol to Symbol
#+begin_notes
Symbol to Symbol benötigt zum differenzieren keine eigentlichen Zahlenwerte, sondern ersetzt diese durch Symbole. \\
Zusammengefasst kann man sagen, dass der Symbol to Number approach nur die Berechnungen ausführt die vom Symbol to Symbol als Graph erstellt werden.
#+end_notes

Beim der Symbol to Symbol Herangehensweise wird zuerst der Graph mit allen Ableitungen mit der Hilfe von symbolischen Werten konstruiert. \\
Später wird dann der Graph mit der Hilfe eines eigenen Algorithmus ausgewertet. \\

#+begin_quote
*Vorteil* \\
Ableitungen eines höheren Grads können berechnet werden, indem man den Back-propagation Algorithmus auf einen bereits abgeleiteten Graphen ausführt.
#+end_quote

** Operationen
#+begin_notes
Wir benutzen Tensoren um eine möglichst generelle Definition des Algorithmus zu beschreiben.
#+end_notes
Wir betrachten einen computational Graph, jede Node in dem Graph repräsentiert eine Variable in Form eines Tensors.

*** Funktionen
#+begin_notes
~get_operation~ Beispiel bei einer Variable, die durch Matrix Multiplikation generiert wird, würde genau diese Operation zurück gegeben werden.
#+end_notes

- ~get_operation()~
- ~get_consumers()~ \\
  Gibt alle Variablen/Operationen zurück, die 'Kinder' von sich selber sind.
- ~get_inputs()~ \\
  Gibt alle Variablen/Operationen zurück, die 'Eltern' von sich selber sind.
- ~bprop()~ \\
  Muss bei jeder Operation implementiert werden.
** Algorithmus
Benötigt ist:
- die Menge aller Variablen $T$, deren Gradienten wir berechnen müssen
- den Graphen $G$
- die Variable $z$, die wir differenzieren wollen

*** Äußere Funktion
Wir definieren $G'$ als alle Variablen, die Vorfahren von $z$, oder Nachfahren von $T$ sind. \\
\\
In ~grad_table~ können wir Variablen Gradients zuweisen. \\

~grad_table[z] = 1~   (da $\frac{\partial z}{\partial z} = 1$)

*** Loop über alle Variablen, deren Gradienten wir berechnen müssen
In jedem Loop rufen wir die Funktion ~build_grad~ auf.
#+BEGIN_SRC python
for v in T:
    build_grad(v, G, G_1, grad_table)
return [grad_table[v] for v in T]
#+END_SRC

*** ~build_grad(v, G, G_1, grad_table)~
#+BEGIN_SRC python
def build_grad(v, G, G_1, grad_table):
    if v in grad_table: return grad_table[v]
    i = 1
    for c in get_consumers(V, G_1):
        op = get_operation(c)
        d = build_grad(c, G, G_1, grad_table)
        g[i] = op.bprop(get_inputs(c, G_1), v, d)
        i += 1
    g = sum(g)
    grad_table[v] = g
    return g
#+END_SRC

*** ~bprop~ Funktion
~op.bprop(inputs, X, G)~ \\
 \\
~inputs~: Liste an Inputs, die wir der Operation zur Verfügung stellen \\
~X~: Input, dessen Ableitung wir berechnen wollen \\
~G~: Gradient des Outputs der Operation

** Beispiel
*** Graph
[[./big_graph_1.jpg]]

*** Bestimmen der Ableitung $\frac{\partial u_1}{\partial u_4}$
[[./big_graph_2.jpg]]

*** Eintragen aller Ableitungen in Graph
[[./big_graph_3.jpg]]

** Generalisierbarkeit
Dadurch ist der Back-propagation Algorithmus sehr allgemein anwendbar. \\

Jede Operation ist für seine eigene Differenzierung verantwortlich und benötigt keine weiteren Informationen.

* Historisches
#+begin_notes
Die Kettenregel stammt aus dem 17ten Jahrhundert.
#+end_notes

- Kettenregel stammt aus dem 17ten Jahrhundert (Leibniz, 1676). \\
- Lineare neurale Netzwerke Mitte des 20ten Jahrhunderts. \\
- Erfolgreiche Experimente mit Back-Propagation (1986)

* Quellen
- Deep Learning (Ian Goodfellow, Yoshua Bengio & Aaron Courville)
- https://medium.com/@14prakash/back-propagation-is-very-simple-who-made-it-complicated-97b794c97e5c
- Wikipedia: https://en.wikipedia.org/wiki/Backpropagation
- Wikipedia: https://en.wikipedia.org/wiki/Delta_rule
