{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Function\n",
    "\n",
    "\n",
    "![test](https://www.i2tutorials.com/wp-content/uploads/2019/09/Deep-learning-25-i2tutorials.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeakyReLU:  [1.0, 0.0, -5.0]  ->  [1.0, 0.0, -1.0]\n",
      "LeakyReLU (deriv):  [1.0, 0.0, -5.0]  ->  [1.0, 1.0, 0.2]\n"
     ]
    }
   ],
   "source": [
    "def relu(z, deriv=False):\n",
    "    activations = []\n",
    "    shape = z.shape\n",
    "    z = z.flatten()\n",
    "    if deriv:  # Return Derivative of Function\n",
    "        \n",
    "        for i in range(len(z)):  # Element Wise\n",
    "            if z[i] >= 0:\n",
    "                activations.append(1)\n",
    "            else:\n",
    "                activations.append(0.2)\n",
    "                \n",
    "        return np.array(activations).reshape(shape)\n",
    "    \n",
    "    for i in range(len(z)):\n",
    "        if z[i] > 0:\n",
    "            activations.append(z[i])\n",
    "        else:\n",
    "            activations.append(0.2 * z[i])\n",
    "            \n",
    "    return np.array(activations).reshape(shape)\n",
    "\n",
    "input = [1.,0.,-5.]\n",
    "print('LeakyReLU: ', input, ' -> ', list(relu(np.array(input))))\n",
    "\n",
    "print('LeakyReLU (deriv): ', input, ' -> ', list(relu(np.array(input), True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight & Bias Initialization\n",
    "\n",
    "Bias Values ($b$) are initialized with $0$.  \n",
    "Weight Values ($w$) are initialized with random values between $min$ and $max$.\n",
    "\n",
    "## Neural Network Structure\n",
    "\n",
    "**Neural Net Structure** `2 (Input) - 3 (Hidden) - 3 (Hidden) - 2 (Output)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Weights:\n",
      " [[ 0.746  0.977 -0.085]\n",
      " [-0.785 -0.842 -0.743]] (Shape: (2, 3))\n",
      "Bias: \n",
      "[0. 0. 0.] (Shape: (3,))\n",
      "\n",
      "Layer 1:\n",
      "Weights:\n",
      " [[-0.796 -0.006  0.032]\n",
      " [ 0.078 -0.052  0.457]\n",
      " [ 0.993  0.848  0.883]] (Shape: (3, 3))\n",
      "Bias: \n",
      "[0. 0. 0.] (Shape: (3,))\n",
      "\n",
      "Layer 2:\n",
      "Weights:\n",
      " [[ 0.544 -0.945]\n",
      " [-0.226  0.87 ]\n",
      " [-0.871 -0.589]] (Shape: (3, 2))\n",
      "Bias: \n",
      "[0. 0.] (Shape: (2,))\n",
      "\n",
      "Layer 3:\n",
      "Weights:\n",
      " [[0.692]\n",
      " [0.387]] (Shape: (2, 1))\n",
      "Bias: \n",
      "[0.] (Shape: (1,))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def initialize(min=0, max=1, do_print=True):\n",
    "    global w, b\n",
    "    w = [\n",
    "            max * np.random.uniform(min, max, (2, 3)),\n",
    "            max * np.random.uniform(min, max, (3, 3)),\n",
    "            max * np.random.uniform(min, max, (3, 2)),\n",
    "            max * np.random.uniform(min, max, (2, 1))\n",
    "        ]\n",
    "    b = [\n",
    "        np.array(np.zeros(3)),\n",
    "        np.array(np.zeros(3)),\n",
    "        np.array(np.zeros(2)),\n",
    "        np.array(np.zeros(1))\n",
    "    ]\n",
    "    if do_print:\n",
    "        for i in range(len(b)): print(f'Layer {i}:\\nWeights:\\n {w[i]} (Shape: {w[i].shape})\\nBias: \\n{b[i]} (Shape: {b[i].shape})\\n')    \n",
    "\n",
    "w, b = [], []\n",
    "\n",
    "initialize(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation\n",
    "List $a$ holds each layers activation vector.  \n",
    "List $z$ holds each layers pre nonlinearity vector.\n",
    "\n",
    "## Algorithm\n",
    "\n",
    "For each layer $L$, starting with $L_0$ we multiply the $h$ vector with the weight matrix $w$.\n",
    "\n",
    "$$\n",
    "w = \\left[ \\begin{array}{rrr}\n",
    "1.3 & 0.2 \\\\                                              \n",
    "0.1 & 1.4 \\\\\n",
    "1.2 & 0 \\\\\n",
    "\\end{array}\\right] \\ \\ \\ \\ \\ \\ \\ \n",
    "h = \\left( \\begin{array}{rrr}\n",
    "1.3 \\\\                                              \n",
    "0.1 \\\\\n",
    "1.2 \\\\\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h:  [[0 1]] (1, 2)\n",
      "Layer 0 | [[0 1]] dot [[0.289 0.406 0.787]\n",
      " [0.666 0.232 0.729]]\n",
      "Layer 1 | [[0.666 0.232 0.729]] dot [[6.192e-04 3.636e-01 5.763e-01]\n",
      " [8.018e-01 5.606e-02 4.077e-01]\n",
      " [5.536e-01 5.455e-01 3.356e-01]]\n",
      "Layer 2 | [[0.59  0.653 0.723]] dot [[0.903 0.748]\n",
      " [0.943 0.387]\n",
      " [0.318 0.345]]\n",
      "Layer 3 | [[1.378 0.943]] dot [[0.361]\n",
      " [0.164]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.652]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, z = [], []  # Global Variables\n",
    "\n",
    "initialize(do_print=False)  # Weight & Bias Initialization\n",
    "\n",
    "def forward_prop(X, do_print=False):\n",
    "    h = np.array([X])\n",
    "    if do_print: print('h: ', h, h.shape)\n",
    "    global a, z\n",
    "    a,z  = [], []\n",
    "    for i in range(len(w)):\n",
    "        if do_print: print(f'Layer {i} | {h} dot {w[i]}')\n",
    "        h = h @ w[i] # weigt * input\n",
    "        h = h + b[i] # bias add\n",
    "        z.append(h)\n",
    "        h = relu(h) # Activation Function\n",
    "        a.append(h)\n",
    "    return h\n",
    "\n",
    "forward_prop(np.array([0,1]), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back-propagation\n",
    "\n",
    "\n",
    "$g = loss'(X,y)$\n",
    "\n",
    "## for each layer\n",
    "\n",
    "### Step 1 ($a$ to $z$)\n",
    "\n",
    "$g = relu'(z)$\n",
    "\n",
    "\n",
    "\n",
    "### Step 2 ($z$ to $W$)\n",
    "\n",
    "$g = relu'(z) * a_{L-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.39361445]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.07746617])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.05\n",
    "\n",
    "initialize(do_print=False)\n",
    "\n",
    "def back_prop(X, y, print_loss=False):\n",
    "    global a, z, w, b\n",
    "\n",
    "    loss = 0.5*(y - X)**2  #  Calculate Loss Value\n",
    "    g = (X - y).reshape(1,-1).T  # Loss Function Derivative\n",
    "    \n",
    "    if print_loss:  # Print Loss \n",
    "        print(\"Loss: \", (y - X)**2)\n",
    "    \n",
    "    n_weights, n_bias = [], []\n",
    "    \n",
    "    for x in range(len(w)):  # Iterate through NN Layers\n",
    "        i = len(b) - 1 - x  # Reverse Index\n",
    "\n",
    "        # Activation Function Derivative \n",
    "        g = g * relu(z[i], True)  # Activation Function Derivative\n",
    "        \n",
    "        # Derivative with respect to weight\n",
    "        if i-1 < 0: w_der = y.reshape(1,-1).T\n",
    "        else: w_der = a[i-1].reshape(1,-1).T  # Previous Layer Activation\n",
    "        \n",
    "        # Change in Weights & Bias\n",
    "        n_weights.append(w[i] - learning_rate * (w_der @ g))\n",
    "        n_bias.append(b[i] - learning_rate * g)\n",
    "        \n",
    "        # Deriv for next Layer\n",
    "        g = g @ w[i].T \n",
    "    \n",
    "    # Updating Weights\n",
    "    w = list(reversed(n_weights))\n",
    "    b = list(reversed(n_bias))\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "X = forward_prop(np.array([0,1]))\n",
    "print(X)\n",
    "back_prop(X, np.array([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function\n",
    "\n",
    "## Adding 2 Numbers\n",
    "\n",
    "We train a simple Function $f^*(x)=x_1+x_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss:  [0.014]\n",
      "Epoch 1 | Loss:  [4.835e-05]\n",
      "Epoch 2 | Loss:  [3.136e-05]\n",
      "Epoch 3 | Loss:  [2.846e-05]\n",
      "Epoch 4 | Loss:  [2.4e-05]\n",
      "Epoch 5 | Loss:  [2.497e-05]\n",
      "Epoch 6 | Loss:  [2.929e-05]\n",
      "Epoch 7 | Loss:  [3.049e-05]\n",
      "Epoch 8 | Loss:  [2.423e-05]\n",
      "Epoch 9 | Loss:  [2.968e-05]\n",
      "Epoch 10 | Loss:  [2.634e-05]\n",
      "Epoch 11 | Loss:  [2.389e-05]\n",
      "Epoch 12 | Loss:  [1.908e-05]\n",
      "Epoch 13 | Loss:  [2.024e-05]\n",
      "Epoch 14 | Loss:  [2.019e-05]\n",
      "Epoch 15 | Loss:  [1.746e-05]\n",
      "Epoch 16 | Loss:  [2.067e-05]\n",
      "Epoch 17 | Loss:  [1.663e-05]\n",
      "Epoch 18 | Loss:  [1.882e-05]\n",
      "Epoch 19 | Loss:  [1.815e-05]\n",
      "\n",
      "Input:\n",
      "[[0.2 0.3]\n",
      " [0.7 0.2]\n",
      " [1.  0. ]\n",
      " [1.  1. ]] \n",
      "Output:\n",
      "[[0.497]\n",
      " [0.901]\n",
      " [1.005]\n",
      " [1.997]]\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "def train(epochs, size=100):\n",
    "    for i in range(epochs):\n",
    "        tmp = 0.0\n",
    "        for x in range(size):\n",
    "            y1 = randint(0,1)  # X1\n",
    "            y2 = randint(0,1)  # X2\n",
    "            tmp += back_prop(forward_prop(np.array([y1,y2])), np.array([y1+y2]))[0]\n",
    "        print(f'Epoch {i} | Loss: ', tmp/size)\n",
    "\n",
    "initialize(do_print=False)\n",
    "train(20, 100)\n",
    "\n",
    "print('\\nInput:')\n",
    "print(np.array([[0.2,0.3], \n",
    "     [0.7, 0.2], \n",
    "     [1.,0.], \n",
    "     [1,1]]), '\\nOutput:')\n",
    "print(forward_prop(np.array([[0.2,0.3], \n",
    "                             [0.7, 0.2], \n",
    "                             [1.,0.], \n",
    "                             [1,1]]))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  [0.123]\n",
      "Loss:  [0.112]\n",
      "Loss:  [0.13]\n",
      "Loss:  [0.124]\n",
      "Loss:  [0.086]\n",
      "Loss:  [0.063]\n",
      "Loss:  [0.035]\n",
      "Loss:  [0.05]\n",
      "Loss:  [0.032]\n",
      "Loss:  [0.06]\n",
      "Loss:  [0.143]\n",
      "Loss:  [0.136]\n",
      "Loss:  [0.096]\n",
      "Loss:  [0.003]\n",
      "Loss:  [0.001]\n",
      "Loss:  [0.001]\n",
      "Loss:  [0.]\n",
      "Loss:  [0.]\n",
      "Loss:  [0.]\n",
      "Loss:  [6.934e-05]\n",
      "[[1.015]]\n",
      "[[0.988]]\n",
      "[[0.]]\n",
      "[[-0.001]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12098fa90>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [\n",
    "    [0,1],\n",
    "    [0,0],\n",
    "    [1,0],\n",
    "    [1,1]\n",
    "]   # Design Matrix \n",
    "\n",
    "y = [1,0,1,0]    # Labels\n",
    "\n",
    "initialize(-1, 1, do_print=False)  # Reinitialize\n",
    "\n",
    "def train(epochs, size=100):\n",
    "    l = []\n",
    "    for i in range(epochs):\n",
    "        tmp = 0.0\n",
    "        for x in range(size):\n",
    "            y1 = randint(0,3)\n",
    "            tmp += back_prop(forward_prop(np.array(X[y1])), np.array(y[y1]))[0]\n",
    "        l.append(tmp/size)\n",
    "        print(\"Loss: \", tmp/size)\n",
    "        if tmp/size < 0.0001: break\n",
    "    return np.array(l).flatten()\n",
    "\n",
    "loss_over_time =  train(300,600)\n",
    "\n",
    "print(forward_prop(np.array([1,0])))\n",
    "print(forward_prop(np.array([0,1])))\n",
    "print(forward_prop(np.array([0,0])))\n",
    "print(forward_prop(np.array([1,1])))\n",
    "\n",
    "plt.plot(loss_over_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Backpropagation Implementation\n",
    "Exmaple: Learning XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Loss: [0.13]\n",
      "[Epoch 1] Loss: [0.129]\n",
      "[Epoch 2] Loss: [0.128]\n",
      "[Epoch 3] Loss: [0.128]\n",
      "[Epoch 4] Loss: [0.128]\n",
      "[Epoch 5] Loss: [0.129]\n",
      "[Epoch 6] Loss: [0.128]\n",
      "[Epoch 7] Loss: [0.128]\n",
      "[Epoch 8] Loss: [0.128]\n",
      "[Epoch 9] Loss: [0.127]\n",
      "[Epoch 10] Loss: [0.119]\n",
      "[Epoch 11] Loss: [0.096]\n",
      "[Epoch 12] Loss: [0.097]\n",
      "[Epoch 13] Loss: [0.094]\n",
      "[Epoch 14] Loss: [0.091]\n",
      "[Epoch 15] Loss: [0.092]\n",
      "[Epoch 16] Loss: [0.093]\n",
      "[Epoch 17] Loss: [0.09]\n",
      "[Epoch 18] Loss: [0.083]\n",
      "[Epoch 19] Loss: [0.011]\n",
      "[Epoch 20] Loss: [2.232e-07]\n",
      "[[[1.000e+00]\n",
      "  [1.000e+00]\n",
      "  [4.996e-06]\n",
      "  [5.688e-07]]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "\n",
    "\n",
    "def backprop_entry(X, y, print_loss=False):\n",
    "    global a, z, w, b, n_weights, n_bias\n",
    "    n_weights, n_bias = [], []\n",
    "    \n",
    "    backprop_rec(0, X, y)\n",
    "    \n",
    "    # Update Weights\n",
    "    w = list(reversed(n_weights))\n",
    "    b = list(reversed(n_bias))\n",
    "    return 0.5*(y - X)**2  # Return Loss\n",
    "\n",
    "\n",
    "def backprop_rec(i, X, y):\n",
    "    global a, z, w, b, n_weights, n_bias\n",
    "\n",
    "    # Base Case\n",
    "    if i+1 > len(w): return (X - y).reshape(1,-1).T\n",
    "    \n",
    "    g = backprop_rec(i+1, X, y) * relu(z[i], True)  # Get Next Layer Derivative\n",
    "    \n",
    "    # Derivative with respect to weight [1xn]  \n",
    "    if i-1 < 0: w_der = y.reshape(1,-1).T  # Input Matrix\n",
    "    else: w_der = a[i-1].reshape(1,-1).T  # Previous Layer Activation\n",
    "\n",
    "    # Save change in weights\n",
    "    n_weights.append(w[i] - learning_rate * (w_der @ g))\n",
    "    n_bias.append(b[i] - learning_rate * g)\n",
    "    \n",
    "    return g @ w[i].T \n",
    "\n",
    "def train_rec(epochs, size=100, threshold=0.0001):\n",
    "    l = []\n",
    "    for i in range(epochs):\n",
    "        sum_loss = 0.0\n",
    "        for x in range(size):\n",
    "            y1 = randint(0,3)\n",
    "            \n",
    "            sum_loss += backprop_entry(forward_prop(np.array(X[y1])), np.array(y[y1]))[0]\n",
    "        l.append(sum_loss/size)\n",
    "        print(f'[Epoch {i}] Loss: {l[-1]}')\n",
    "        if l[-1] < threshold or l[-1] != l[-1]: break\n",
    "    return np.array(l).flatten()\n",
    "\n",
    "# Reinitialize Weights & Bias\n",
    "initialize(-1, 1, do_print=False)\n",
    "\n",
    "loss_over_time = train_rec(200,1000)\n",
    "\n",
    "\n",
    "print(forward_prop(np.array([[1,0], \n",
    "                             [0,1], \n",
    "                             [1,1], \n",
    "                             [0,0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "name": "Minimal Backprop.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
