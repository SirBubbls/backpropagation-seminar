{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions\n",
    "\n",
    "\n",
    "![test](https://www.i2tutorials.com/wp-content/uploads/2019/09/Deep-learning-25-i2tutorials.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def relu(z, deriv=False):\n",
    "    activations = []\n",
    "    shape = z.shape\n",
    "    z = z.flatten()\n",
    "    if deriv:\n",
    "        for i in range(len(z)):\n",
    "            if z[i] >= 0:\n",
    "                activations.append(1)\n",
    "            else:\n",
    "                activations.append(-0.2)\n",
    "        return np.array(activations).reshape(shape)\n",
    "    for i in range(len(z)):\n",
    "        if z[i] > 0:\n",
    "            activations.append(z[i])\n",
    "        else:\n",
    "            activations.append(-0.2 * z[i])\n",
    "    return np.array(activations).reshape(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight & Bias Initialization\n",
    "\n",
    "Bias Values ($b$) are initialized with $0$.  \n",
    "Weight Values ($w$) are initialized with random values between $-2$ and $2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Weights:\n",
      " [[0.24546327 0.62250386 0.39528455]\n",
      " [0.34376932 0.6027192  0.84442436]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 1:\n",
      "Weights:\n",
      " [[0.40082913 0.48342315 0.17930616]\n",
      " [0.74440985 0.17694403 0.71328436]\n",
      " [0.21824271 0.33972611 0.64358872]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 2:\n",
      "Weights:\n",
      " [[0.34894669 0.86454484]\n",
      " [0.61205193 0.01778507]\n",
      " [0.40488679 0.61820124]]\n",
      "Bias: \n",
      "[0. 0.]\n",
      "\n",
      "Layer 3:\n",
      "Weights:\n",
      " [[0.1099028 ]\n",
      " [0.61903641]]\n",
      "Bias: \n",
      "[0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def initialize(min=0, max=1):\n",
    "    global w, b\n",
    "#     w = [\n",
    "#         max * np.random.randn(2, 3) + min,\n",
    "#         max * np.random.randn(3, 3) + min,\n",
    "#         max * np.random.randn(3, 2) + min,\n",
    "#         max * np.random.randn(2, 1) + min\n",
    "#     ]\n",
    "    w = [\n",
    "            max * np.random.uniform(min, max, (2, 3)),\n",
    "            max * np.random.uniform(min, max, (3, 3)),\n",
    "            max * np.random.uniform(min, max, (3, 2)),\n",
    "            max * np.random.uniform(min, max, (2, 1))\n",
    "        ]\n",
    "    b = [\n",
    "        np.array(np.zeros(3)),\n",
    "        np.array(np.zeros(3)),\n",
    "        np.array(np.zeros(2)),\n",
    "        np.array(np.zeros(1))\n",
    "    ]\n",
    "    for i in range(len(b)): print(f'Layer {i}:\\nWeights:\\n {w[i]}\\nBias: \\n{b[i]}\\n')    \n",
    "\n",
    "w, b = [], []\n",
    "\n",
    "initialize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation\n",
    "$a$ holds each layers activation vector.  \n",
    "$z$ holds each layers pre nonlinearity vector.\n",
    "\n",
    "## Algorithm\n",
    "\n",
    "For each layer $L$, starting with $L_0$ we multiply the $h$ vector with the weight matrix $w$.\n",
    "\n",
    "$$\n",
    "w = \\left[ \\begin{array}{rrr}\n",
    "1.3 & 0.2 \\\\                                              \n",
    "0.1 & 1.4 \\\\\n",
    "1.2 & 0 \\\\\n",
    "\\end{array}\\right] \\ \\ \\ \\ \\ \\ \\ \n",
    "h = \\left( \\begin{array}{rrr}\n",
    "1.3 \\\\                                              \n",
    "0.1 \\\\\n",
    "1.2 \\\\\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14376148])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, z = [], []\n",
    "\n",
    "initialize()\n",
    "\n",
    "def forward_prop(X):\n",
    "    h = X\n",
    "    global a, z\n",
    "    a,z  = [], []\n",
    "    for i in range(len(w)):\n",
    "        h = h @ w[i] # weigt * input\n",
    "        h = h + b[i] # bias add\n",
    "        z.append(h)\n",
    "        h = relu(h) # Activation Function\n",
    "        a.append(h)\n",
    "    return h\n",
    "\n",
    "forward_prop(np.array([0,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Prop\n",
    "\n",
    "for each layer\n",
    "\n",
    "$g = loss'(X,y)$\n",
    "\n",
    "## Step 1 ($a$ to $z$)\n",
    "\n",
    "$g = relu'(z)$\n",
    "\n",
    "\n",
    "\n",
    "## Step 2 ($z$ to $W$)\n",
    "\n",
    "$g = relu'(z) * a_{L-1}$\n",
    "\n",
    "# Dimensions\n",
    "\n",
    "$g = [1\\times2]$\n",
    "\n",
    "## Step 1 Activation Function Derriv\n",
    "\n",
    "$g = [1\\times2]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Weights:\n",
      " [[-0.51666303  0.12744667 -0.74715203]\n",
      " [ 0.61821264 -0.93676889  0.03960861]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 1:\n",
      "Weights:\n",
      " [[-0.18267017 -0.02219009 -0.00438998]\n",
      " [ 0.85068071 -0.62054631  0.23438947]\n",
      " [ 0.49467297  0.07474434  0.50620963]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 2:\n",
      "Weights:\n",
      " [[-0.90396946 -0.33050226]\n",
      " [-0.49088497  0.34388385]\n",
      " [-0.53414698  0.67032197]]\n",
      "Bias: \n",
      "[0. 0.]\n",
      "\n",
      "Layer 3:\n",
      "Weights:\n",
      " [[0.56379138]\n",
      " [0.74686582]]\n",
      "Bias: \n",
      "[0.]\n",
      "\n",
      "[0.0327138]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.4678213])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.05\n",
    "\n",
    "initialize()\n",
    "\n",
    "def back_prop(X, y, print_loss=False):\n",
    "    global a, z, w, b\n",
    "\n",
    "    g = (X - y).reshape(1,-1).T\n",
    "    loss = 0.5*(y - X)**2\n",
    "    \n",
    "    if print_loss:\n",
    "        print(\"Loss: \", (y - X)**2)\n",
    "    \n",
    "    n_weights, n_bias = [], []\n",
    "    \n",
    "    for x in range(len(w)):\n",
    "        i = len(b) - 1 - x\n",
    "\n",
    "        # Activation Function Derrivative [1xn]\n",
    "        g = g * relu(z[i], True)  # Activation Function Derriv\n",
    "        \n",
    "        # Derivative with respect to weight [1xn]  \n",
    "        if i-1 < 0: w_der = y.reshape(1,-1).T\n",
    "        else: w_der = a[i-1].reshape(1,-1).T  # Previous Layer Activation\n",
    "        \n",
    "        \n",
    "#         print(w_der.shape, g.shape)\n",
    "#         print((w_der @ g).shape)\n",
    "        \n",
    "        # Change in Weights\n",
    "        new_weights = w[i] - learning_rate * (w_der @ g)\n",
    "        n_weights.append(new_weights)\n",
    "        \n",
    "        new_bias = b[i] - learning_rate * g\n",
    "        n_bias.append(new_bias)\n",
    "        \n",
    "        g = g @ w[i].T \n",
    "    \n",
    "    n_weights = list(reversed(n_weights))\n",
    "    n_bias = list(reversed(n_bias))\n",
    "    w = n_weights\n",
    "    b = n_bias\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "X = forward_prop(np.array([0,1]))\n",
    "print(X)\n",
    "back_prop(X, np.array([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Weights:\n",
      " [[ 0.38326112  0.20813528  0.65402631]\n",
      " [-0.60344405 -0.95827159 -0.68812989]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 1:\n",
      "Weights:\n",
      " [[-0.95325366 -0.11602268 -0.71821794]\n",
      " [ 0.66631753  0.25503068  0.67829376]\n",
      " [ 0.08198395 -0.40475491 -0.87494075]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 2:\n",
      "Weights:\n",
      " [[ 0.31007906 -0.02763918]\n",
      " [ 0.32109855  0.46705216]\n",
      " [ 0.19892856 -0.72172763]]\n",
      "Bias: \n",
      "[0. 0.]\n",
      "\n",
      "Layer 3:\n",
      "Weights:\n",
      " [[ 0.97445982]\n",
      " [-0.50544974]]\n",
      "Bias: \n",
      "[0.]\n",
      "\n",
      "Loss:  [0.31662367]\n",
      "Loss:  [0.20629137]\n",
      "Loss:  [0.12505463]\n",
      "Loss:  [0.10846328]\n",
      "Loss:  [0.36172064]\n",
      "Loss:  [0.30606753]\n",
      "Loss:  [0.28201808]\n",
      "Loss:  [0.22351974]\n",
      "Loss:  [0.19475317]\n",
      "Loss:  [0.12504714]\n",
      "Loss:  [0.09297734]\n",
      "Loss:  [0.03374398]\n",
      "Loss:  [0.01372965]\n",
      "Loss:  [0.00697562]\n",
      "Loss:  [0.00360523]\n",
      "Loss:  [0.00190138]\n",
      "Loss:  [0.00132749]\n",
      "Loss:  [0.00064864]\n",
      "Loss:  [0.00039781]\n",
      "Loss:  [0.00019196]\n",
      "[[0.57059579]]\n",
      "[[0.92424873]]\n",
      "[[0.98530438]]\n",
      "[[1.99989214]]\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "def train(epochs, size=100):\n",
    "    for i in range(epochs):\n",
    "        tmp = 0.0\n",
    "        for x in range(size):\n",
    "            y1 = randint(0,1)\n",
    "            y2 = randint(0,1)\n",
    "            tmp += back_prop(forward_prop(np.array([y1,y2])), np.array([y1+y2]))[0]\n",
    "        print(\"Loss: \", tmp/size)\n",
    "\n",
    "initialize()\n",
    "train(20, 100)\n",
    "print(forward_prop(np.array([0.2,0.3])))\n",
    "print(forward_prop(np.array([0.7,0.2])))\n",
    "print(forward_prop(np.array([1,0])))\n",
    "print(forward_prop(np.array([1,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Weights:\n",
      " [[ 0.94350544 -0.55698302 -0.26304013]\n",
      " [ 0.46307711  0.16516881  0.17666339]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 1:\n",
      "Weights:\n",
      " [[ 0.31251327  0.97904368  0.00668538]\n",
      " [-0.05963812 -0.95574112 -0.23194124]\n",
      " [-0.46105712 -0.28054532 -0.77382726]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 2:\n",
      "Weights:\n",
      " [[ 0.96223816  0.35777967]\n",
      " [ 0.96380666 -0.6956461 ]\n",
      " [ 0.86384591  0.90705638]]\n",
      "Bias: \n",
      "[0. 0.]\n",
      "\n",
      "Layer 3:\n",
      "Weights:\n",
      " [[-0.32547874]\n",
      " [-0.67682821]]\n",
      "Bias: \n",
      "[0.]\n",
      "\n",
      "Loss:  [0.14668793]\n",
      "Loss:  [0.12940773]\n",
      "Loss:  [0.12666134]\n",
      "Loss:  [0.1271242]\n",
      "Loss:  [0.12603402]\n",
      "Loss:  [0.12539405]\n",
      "Loss:  [0.12573901]\n",
      "Loss:  [0.12451635]\n",
      "Loss:  [0.12586103]\n",
      "Loss:  [0.12475062]\n",
      "[[0.46646867]]\n",
      "[[0.47910771]]\n",
      "[[0.47651364]]\n",
      "[[0.46278725]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1220bc7d0>]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [\n",
    "    [0,1],\n",
    "    [0,0],\n",
    "    [1,0],\n",
    "    [1,1]\n",
    "]\n",
    "\n",
    "y = [1,0,1,0]\n",
    "\n",
    "initialize(-1, 1)\n",
    "\n",
    "def train(epochs, size=100):\n",
    "    l = []\n",
    "    for i in range(epochs):\n",
    "        tmp = 0.0\n",
    "        for x in range(size):\n",
    "            y1 = randint(0,3)\n",
    "            tmp += back_prop(forward_prop(np.array(X[y1])), np.array(y[y1]))[0]\n",
    "        l.append(tmp/size)\n",
    "        print(\"Loss: \", tmp/size)\n",
    "    return np.array(l).flatten()\n",
    "\n",
    "loss_over_time =  train(10,1000)\n",
    "\n",
    "print(forward_prop(np.array([1,0])))\n",
    "print(forward_prop(np.array([0,1])))\n",
    "print(forward_prop(np.array([0,0])))\n",
    "print(forward_prop(np.array([1,1])))\n",
    "\n",
    "plt.plot(loss_over_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00],\n",
       "       [2.28705943e-15],\n",
       "       [1.00000000e+00],\n",
       "       [5.55111512e-16]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_prop(np.array(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (16,1) (4,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-eadcb175a947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-121-bd45d526e74f>\u001b[0m in \u001b[0;36mback_prop\u001b[0;34m(X, y, print_loss)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Activation Function Derrivative [1xn]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Activation Function Derriv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Derivative with respect to weight [1xn]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (16,1) (4,1) "
     ]
    }
   ],
   "source": [
    "back_prop(forward_prop(np.array(X)), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.14814429,  1.92823901, -2.06791328],\n",
       "        [-0.97452615, -0.0620619 , -3.26824922]]),\n",
       " array([[ 0.572514  , -0.15953226, -0.44648438],\n",
       "        [-1.74452763, -1.99973026, -0.06683409],\n",
       "        [-0.65625722,  0.14834307, -2.67960944]]),\n",
       " array([[ 1.80100234, -0.28922883],\n",
       "        [-0.03161335,  2.26802412],\n",
       "        [ 1.73792913, -2.65500696]]),\n",
       " array([[-5.27508321],\n",
       "        [ 2.62224999]])]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "name": "Minimal Backprop.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
