{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Functions\n",
    "\n",
    "\n",
    "![test](https://www.i2tutorials.com/wp-content/uploads/2019/09/Deep-learning-25-i2tutorials.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def relu(z, deriv=False):\n",
    "    activations = []\n",
    "    shape = z.shape\n",
    "    z = z.flatten()\n",
    "    if deriv:\n",
    "        for i in range(len(z)):\n",
    "            if z[i] >= 0:\n",
    "                activations.append(1)\n",
    "            else:\n",
    "                activations.append(-0.2)\n",
    "        return np.array(activations).reshape(shape)\n",
    "    for i in range(len(z)):\n",
    "        if z[i] > 0:\n",
    "            activations.append(z[i])\n",
    "        else:\n",
    "            activations.append(-0.2 * z[i])\n",
    "    return np.array(activations).reshape(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight & Bias Initialization\n",
    "\n",
    "Bias Values ($b$) are initialized with $0$.  \n",
    "Weight Values ($w$) are initialized with random values between $-2$ and $2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Weights:\n",
      " [[0.24546327 0.62250386 0.39528455]\n",
      " [0.34376932 0.6027192  0.84442436]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 1:\n",
      "Weights:\n",
      " [[0.40082913 0.48342315 0.17930616]\n",
      " [0.74440985 0.17694403 0.71328436]\n",
      " [0.21824271 0.33972611 0.64358872]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 2:\n",
      "Weights:\n",
      " [[0.34894669 0.86454484]\n",
      " [0.61205193 0.01778507]\n",
      " [0.40488679 0.61820124]]\n",
      "Bias: \n",
      "[0. 0.]\n",
      "\n",
      "Layer 3:\n",
      "Weights:\n",
      " [[0.1099028 ]\n",
      " [0.61903641]]\n",
      "Bias: \n",
      "[0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def initialize(min=0, max=1):\n",
    "    global w, b\n",
    "#     w = [\n",
    "#         max * np.random.randn(2, 3) + min,\n",
    "#         max * np.random.randn(3, 3) + min,\n",
    "#         max * np.random.randn(3, 2) + min,\n",
    "#         max * np.random.randn(2, 1) + min\n",
    "#     ]\n",
    "    w = [\n",
    "            max * np.random.uniform(min, max, (2, 3)),\n",
    "            max * np.random.uniform(min, max, (3, 3)),\n",
    "            max * np.random.uniform(min, max, (3, 2)),\n",
    "            max * np.random.uniform(min, max, (2, 1))\n",
    "        ]\n",
    "    b = [\n",
    "        np.array(np.zeros(3)),\n",
    "        np.array(np.zeros(3)),\n",
    "        np.array(np.zeros(2)),\n",
    "        np.array(np.zeros(1))\n",
    "    ]\n",
    "    for i in range(len(b)): print(f'Layer {i}:\\nWeights:\\n {w[i]}\\nBias: \\n{b[i]}\\n')    \n",
    "\n",
    "w, b = [], []\n",
    "\n",
    "initialize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation\n",
    "$a$ holds each layers activation vector.  \n",
    "$z$ holds each layers pre nonlinearity vector.\n",
    "\n",
    "## Algorithm\n",
    "\n",
    "For each layer $L$, starting with $L_0$ we multiply the $h$ vector with the weight matrix $w$.\n",
    "\n",
    "$$\n",
    "w = \\left[ \\begin{array}{rrr}\n",
    "1.3 & 0.2 \\\\                                              \n",
    "0.1 & 1.4 \\\\\n",
    "1.2 & 0 \\\\\n",
    "\\end{array}\\right] \\ \\ \\ \\ \\ \\ \\ \n",
    "h = \\left( \\begin{array}{rrr}\n",
    "1.3 \\\\                                              \n",
    "0.1 \\\\\n",
    "1.2 \\\\\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Weights:\n",
      " [[0.96063305 0.94463216 0.90437261]\n",
      " [0.02254976 0.63848944 0.23344068]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 1:\n",
      "Weights:\n",
      " [[0.05448832 0.69212919 0.91454995]\n",
      " [0.93249491 0.51389037 0.69454665]\n",
      " [0.92066393 0.06377282 0.26062399]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 2:\n",
      "Weights:\n",
      " [[0.27826529 0.83146832]\n",
      " [0.55845366 0.95305448]\n",
      " [0.47480707 0.51586158]]\n",
      "Bias: \n",
      "[0. 0.]\n",
      "\n",
      "Layer 3:\n",
      "Weights:\n",
      " [[0.21724967]\n",
      " [0.24320008]]\n",
      "Bias: \n",
      "[0.]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.4597928])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, z = [], []\n",
    "\n",
    "initialize()\n",
    "\n",
    "def forward_prop(X):\n",
    "    h = X\n",
    "    global a, z\n",
    "    a,z  = [], []\n",
    "    for i in range(len(w)):\n",
    "        h = h @ w[i] # weigt * input\n",
    "        h = h + b[i] # bias add\n",
    "        z.append(h)\n",
    "        h = relu(h) # Activation Function\n",
    "        a.append(h)\n",
    "    return h\n",
    "\n",
    "forward_prop(np.array([0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Prop\n",
    "\n",
    "for each layer\n",
    "\n",
    "$g = loss'(X,y)$\n",
    "\n",
    "## Step 1 ($a$ to $z$)\n",
    "\n",
    "$g = relu'(z)$\n",
    "\n",
    "\n",
    "\n",
    "## Step 2 ($z$ to $W$)\n",
    "\n",
    "$g = relu'(z) * a_{L-1}$\n",
    "\n",
    "# Dimensions\n",
    "\n",
    "$g = [1\\times2]$\n",
    "\n",
    "## Step 1 Activation Function Derriv\n",
    "\n",
    "$g = [1\\times2]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Weights:\n",
      " [[-0.51666303  0.12744667 -0.74715203]\n",
      " [ 0.61821264 -0.93676889  0.03960861]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 1:\n",
      "Weights:\n",
      " [[-0.18267017 -0.02219009 -0.00438998]\n",
      " [ 0.85068071 -0.62054631  0.23438947]\n",
      " [ 0.49467297  0.07474434  0.50620963]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 2:\n",
      "Weights:\n",
      " [[-0.90396946 -0.33050226]\n",
      " [-0.49088497  0.34388385]\n",
      " [-0.53414698  0.67032197]]\n",
      "Bias: \n",
      "[0. 0.]\n",
      "\n",
      "Layer 3:\n",
      "Weights:\n",
      " [[0.56379138]\n",
      " [0.74686582]]\n",
      "Bias: \n",
      "[0.]\n",
      "\n",
      "[0.0327138]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.4678213])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.05\n",
    "\n",
    "initialize()\n",
    "\n",
    "def back_prop(X, y, print_loss=False):\n",
    "    global a, z, w, b\n",
    "\n",
    "    g = (X - y).reshape(1,-1).T\n",
    "    loss = 0.5*(y - X)**2\n",
    "    \n",
    "    if print_loss:y\n",
    "        print(\"Loss: \", (y - X)**2)\n",
    "    \n",
    "    n_weights, n_bias = [], []\n",
    "    \n",
    "    for x in range(len(w)):\n",
    "        i = len(b) - 1 - x\n",
    "\n",
    "        # Activation Function Derrivative [1xn]\n",
    "        g = g * relu(z[i], True)  # Activation Function Derriv\n",
    "        \n",
    "        # Derivative with respect to weight [1xn]  \n",
    "        if i-1 < 0: w_der = y.reshape(1,-1).T\n",
    "        else: w_der = a[i-1].reshape(1,-1).T  # Previous Layer Activation\n",
    "        \n",
    "        \n",
    "#         print(w_der.shape, g.shape)\n",
    "#         print((w_der @ g).shape)\n",
    "        \n",
    "        # Change in Weights\n",
    "        new_weights = w[i] - learning_rate * (w_der @ g)\n",
    "        n_weights.append(new_weights)\n",
    "        \n",
    "        new_bias = b[i] - learning_rate * g\n",
    "        n_bias.append(new_bias)\n",
    "        \n",
    "        g = g @ w[i].T \n",
    "    \n",
    "    n_weights = list(reversed(n_weights))\n",
    "    n_bias = list(reversed(n_bias))\n",
    "    w = n_weights\n",
    "    b = n_bias\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "X = forward_prop(np.array([0,1]))\n",
    "print(X)\n",
    "back_prop(X, np.array([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Weights:\n",
      " [[ 0.38326112  0.20813528  0.65402631]\n",
      " [-0.60344405 -0.95827159 -0.68812989]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 1:\n",
      "Weights:\n",
      " [[-0.95325366 -0.11602268 -0.71821794]\n",
      " [ 0.66631753  0.25503068  0.67829376]\n",
      " [ 0.08198395 -0.40475491 -0.87494075]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 2:\n",
      "Weights:\n",
      " [[ 0.31007906 -0.02763918]\n",
      " [ 0.32109855  0.46705216]\n",
      " [ 0.19892856 -0.72172763]]\n",
      "Bias: \n",
      "[0. 0.]\n",
      "\n",
      "Layer 3:\n",
      "Weights:\n",
      " [[ 0.97445982]\n",
      " [-0.50544974]]\n",
      "Bias: \n",
      "[0.]\n",
      "\n",
      "Loss:  [0.31662367]\n",
      "Loss:  [0.20629137]\n",
      "Loss:  [0.12505463]\n",
      "Loss:  [0.10846328]\n",
      "Loss:  [0.36172064]\n",
      "Loss:  [0.30606753]\n",
      "Loss:  [0.28201808]\n",
      "Loss:  [0.22351974]\n",
      "Loss:  [0.19475317]\n",
      "Loss:  [0.12504714]\n",
      "Loss:  [0.09297734]\n",
      "Loss:  [0.03374398]\n",
      "Loss:  [0.01372965]\n",
      "Loss:  [0.00697562]\n",
      "Loss:  [0.00360523]\n",
      "Loss:  [0.00190138]\n",
      "Loss:  [0.00132749]\n",
      "Loss:  [0.00064864]\n",
      "Loss:  [0.00039781]\n",
      "Loss:  [0.00019196]\n",
      "[[0.57059579]]\n",
      "[[0.92424873]]\n",
      "[[0.98530438]]\n",
      "[[1.99989214]]\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "def train(epochs, size=100):\n",
    "    for i in range(epochs):\n",
    "        tmp = 0.0\n",
    "        for x in range(size):\n",
    "            y1 = randint(0,1)\n",
    "            y2 = randint(0,1)\n",
    "            tmp += back_prop(forward_prop(np.array([y1,y2])), np.array([y1+y2]))[0]\n",
    "        print(\"Loss: \", tmp/size)\n",
    "\n",
    "initialize()\n",
    "train(20, 100)\n",
    "print(forward_prop(np.array([0.2,0.3])))\n",
    "print(forward_prop(np.array([0.7,0.2])))\n",
    "print(forward_prop(np.array([1,0])))\n",
    "print(forward_prop(np.array([1,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Weights:\n",
      " [[ 0.07243197  0.92949268 -0.5681808 ]\n",
      " [-0.49274022  0.16899668 -0.9631557 ]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 1:\n",
      "Weights:\n",
      " [[-0.91423824  0.33467501 -0.75320216]\n",
      " [ 0.99480763  0.81511452  0.72386541]\n",
      " [-0.50346328  0.26119557 -0.47618035]]\n",
      "Bias: \n",
      "[0. 0. 0.]\n",
      "\n",
      "Layer 2:\n",
      "Weights:\n",
      " [[ 0.77368507 -0.69918731]\n",
      " [ 0.98863491  0.30958704]\n",
      " [ 0.92683733  0.2915784 ]]\n",
      "Bias: \n",
      "[0. 0.]\n",
      "\n",
      "Layer 3:\n",
      "Weights:\n",
      " [[-0.27812338]\n",
      " [-0.61687629]]\n",
      "Bias: \n",
      "[0.]\n",
      "\n",
      "Loss:  [0.14452175]\n",
      "Loss:  [0.11601609]\n",
      "Loss:  [0.03316109]\n",
      "Loss:  [0.00320033]\n",
      "Loss:  [0.00439539]\n",
      "Loss:  [0.00228898]\n",
      "Loss:  [0.00122911]\n",
      "Loss:  [0.00234441]\n",
      "Loss:  [0.00055462]\n",
      "Loss:  [0.00023959]\n",
      "[[0.99167947]]\n",
      "[[0.99624452]]\n",
      "[[0.00207474]]\n",
      "[[0.00285716]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x122335c50>]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [\n",
    "    [0,1],\n",
    "    [0,0],\n",
    "    [1,0],\n",
    "    [1,1]\n",
    "]\n",
    "\n",
    "y = [1,0,1,0]\n",
    "\n",
    "initialize(-1, 1)\n",
    "\n",
    "def train(epochs, size=100):\n",
    "    l = []\n",
    "    for i in range(epochs):\n",
    "        tmp = 0.0\n",
    "        for x in range(size):\n",
    "            y1 = randint(0,3)\n",
    "            tmp += back_prop(forward_prop(np.array(X[y1])), np.array(y[y1]))[0]\n",
    "        l.append(tmp/size)\n",
    "        print(\"Loss: \", tmp/size)\n",
    "    return np.array(l).flatten()\n",
    "\n",
    "loss_over_time =  train(10,1000)\n",
    "\n",
    "print(forward_prop(np.array([1,0])))\n",
    "print(forward_prop(np.array([0,1])))\n",
    "print(forward_prop(np.array([0,0])))\n",
    "print(forward_prop(np.array([1,1])))\n",
    "\n",
    "plt.plot(loss_over_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00],\n",
       "       [2.28705943e-15],\n",
       "       [1.00000000e+00],\n",
       "       [5.55111512e-16]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_prop(np.array(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (16,1) (4,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-eadcb175a947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mback_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-121-bd45d526e74f>\u001b[0m in \u001b[0;36mback_prop\u001b[0;34m(X, y, print_loss)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Activation Function Derrivative [1xn]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Activation Function Derriv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Derivative with respect to weight [1xn]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (16,1) (4,1) "
     ]
    }
   ],
   "source": [
    "back_prop(forward_prop(np.array(X)), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.14814429,  1.92823901, -2.06791328],\n",
       "        [-0.97452615, -0.0620619 , -3.26824922]]),\n",
       " array([[ 0.572514  , -0.15953226, -0.44648438],\n",
       "        [-1.74452763, -1.99973026, -0.06683409],\n",
       "        [-0.65625722,  0.14834307, -2.67960944]]),\n",
       " array([[ 1.80100234, -0.28922883],\n",
       "        [-0.03161335,  2.26802412],\n",
       "        [ 1.73792913, -2.65500696]]),\n",
       " array([[-5.27508321],\n",
       "        [ 2.62224999]])]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "name": "Minimal Backprop.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
