{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Function\n",
    "\n",
    "\n",
    "![test](https://www.i2tutorials.com/wp-content/uploads/2019/09/Deep-learning-25-i2tutorials.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def relu(z, deriv=False):\n",
    "    activations = []\n",
    "    shape = z.shape\n",
    "    z = z.flatten()\n",
    "    if deriv:\n",
    "        for i in range(len(z)):\n",
    "            if z[i] >= 0:\n",
    "                activations.append(1)\n",
    "            else:\n",
    "                activations.append(-0.2)\n",
    "        return np.array(activations).reshape(shape)\n",
    "    for i in range(len(z)):\n",
    "        if z[i] > 0:\n",
    "            activations.append(z[i])\n",
    "        else:\n",
    "            activations.append(-0.2 * z[i])\n",
    "    return np.array(activations).reshape(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight & Bias Initialization\n",
    "\n",
    "Bias Values ($b$) are initialized with $0$.  \n",
    "Weight Values ($w$) are initialized with random values between $min$ and $max$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0:\n",
      "Weights:\n",
      " [[0.14216612 0.24178509 0.84502997]\n",
      " [0.39068893 0.4974539  0.39741117]] (Shape: (2, 3))\n",
      "Bias: \n",
      "[0. 0. 0.] (Shape: (3,))\n",
      "\n",
      "Layer 1:\n",
      "Weights:\n",
      " [[0.72330235 0.0033144  0.12580397]\n",
      " [0.94080328 0.09845043 0.32765839]\n",
      " [0.57797111 0.14685047 0.32416244]] (Shape: (3, 3))\n",
      "Bias: \n",
      "[0. 0. 0.] (Shape: (3,))\n",
      "\n",
      "Layer 2:\n",
      "Weights:\n",
      " [[0.14738033 0.08199288]\n",
      " [0.91855083 0.43405997]\n",
      " [0.51343326 0.5202711 ]] (Shape: (3, 2))\n",
      "Bias: \n",
      "[0. 0.] (Shape: (2,))\n",
      "\n",
      "Layer 3:\n",
      "Weights:\n",
      " [[0.09913388]\n",
      " [0.35936031]] (Shape: (2, 1))\n",
      "Bias: \n",
      "[0.] (Shape: (1,))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def initialize(min=0, max=1, do_print=True):\n",
    "    global w, b\n",
    "    w = [\n",
    "            max * np.random.uniform(min, max, (2, 3)),\n",
    "            max * np.random.uniform(min, max, (3, 3)),\n",
    "            max * np.random.uniform(min, max, (3, 2)),\n",
    "            max * np.random.uniform(min, max, (2, 1))\n",
    "        ]\n",
    "    b = [\n",
    "        np.array(np.zeros(3)),\n",
    "        np.array(np.zeros(3)),\n",
    "        np.array(np.zeros(2)),\n",
    "        np.array(np.zeros(1))\n",
    "    ]\n",
    "    if do_print:\n",
    "        for i in range(len(b)): print(f'Layer {i}:\\nWeights:\\n {w[i]} (Shape: {w[i].shape})\\nBias: \\n{b[i]} (Shape: {b[i].shape})\\n')    \n",
    "\n",
    "w, b = [], []\n",
    "\n",
    "initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Propagation\n",
    "List $a$ holds each layers activation vector.  \n",
    "List $z$ holds each layers pre nonlinearity vector.\n",
    "\n",
    "## Algorithm\n",
    "\n",
    "For each layer $L$, starting with $L_0$ we multiply the $h$ vector with the weight matrix $w$.\n",
    "\n",
    "$$\n",
    "w = \\left[ \\begin{array}{rrr}\n",
    "1.3 & 0.2 \\\\                                              \n",
    "0.1 & 1.4 \\\\\n",
    "1.2 & 0 \\\\\n",
    "\\end{array}\\right] \\ \\ \\ \\ \\ \\ \\ \n",
    "h = \\left( \\begin{array}{rrr}\n",
    "1.3 \\\\                                              \n",
    "0.1 \\\\\n",
    "1.2 \\\\\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.44610694])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, z = [], []\n",
    "\n",
    "initialize(do_print=False)\n",
    "\n",
    "def forward_prop(X):\n",
    "    h = X\n",
    "    global a, z\n",
    "    a,z  = [], []\n",
    "    for i in range(len(w)):\n",
    "        h = h @ w[i] # weigt * input\n",
    "        h = h + b[i] # bias add\n",
    "        z.append(h)\n",
    "        h = relu(h) # Activation Function\n",
    "        a.append(h)\n",
    "    return h\n",
    "\n",
    "forward_prop(np.array([0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Prop\n",
    "\n",
    "for each layer\n",
    "\n",
    "$g = loss'(X,y)$\n",
    "\n",
    "## Step 1 ($a$ to $z$)\n",
    "\n",
    "$g = relu'(z)$\n",
    "\n",
    "\n",
    "\n",
    "## Step 2 ($z$ to $W$)\n",
    "\n",
    "$g = relu'(z) * a_{L-1}$\n",
    "\n",
    "\n",
    "## Step 1 Activation Function Deriv\n",
    "\n",
    "$g = [1\\times2]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.15187405]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.01153286])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.05\n",
    "\n",
    "initialize(do_print=False)\n",
    "\n",
    "def back_prop(X, y, print_loss=False):\n",
    "    global a, z, w, b\n",
    "\n",
    "    g = (X - y).reshape(1,-1).T  # Loss Function Derivative\n",
    "    loss = 0.5*(y - X)**2\n",
    "    \n",
    "    if print_loss:\n",
    "        print(\"Loss: \", (y - X)**2)\n",
    "    \n",
    "    n_weights, n_bias = [], []\n",
    "    \n",
    "    for x in range(len(w)):\n",
    "        i = len(b) - 1 - x  # Reverse Index\n",
    "\n",
    "        # Activation Function Derivative \n",
    "        g = g * relu(z[i], True)  # Activation Function Derivative\n",
    "        \n",
    "        # Derivative with respect to weight\n",
    "        if i-1 < 0: w_der = y.reshape(1,-1).T\n",
    "        else: w_der = a[i-1].reshape(1,-1).T  # Previous Layer Activation\n",
    "        \n",
    "        # Change in Weights & Bias\n",
    "        n_weights.append(w[i] - learning_rate * (w_der @ g))\n",
    "        n_bias.append(b[i] - learning_rate * g)\n",
    "        \n",
    "        g = g @ w[i].T \n",
    "    \n",
    "    # Updating Weights\n",
    "    w = list(reversed(n_weights))\n",
    "    b = list(reversed(n_bias))\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "X = forward_prop(np.array([0,1]))\n",
    "print(X)\n",
    "back_prop(X, np.array([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  [0.063]\n",
      "Loss:  [0.031]\n",
      "Loss:  [0.024]\n",
      "Loss:  [0.013]\n",
      "Loss:  [0.01]\n",
      "Loss:  [0.004]\n",
      "Loss:  [0.002]\n",
      "Loss:  [0.001]\n",
      "Loss:  [0.]\n",
      "Loss:  [7.832e-05]\n",
      "Loss:  [2.371e-05]\n",
      "Loss:  [8.578e-06]\n",
      "Loss:  [2.191e-06]\n",
      "Loss:  [5.606e-07]\n",
      "Loss:  [2.347e-07]\n",
      "Loss:  [1.008e-07]\n",
      "Loss:  [7.768e-08]\n",
      "Loss:  [3.907e-08]\n",
      "Loss:  [2.81e-08]\n",
      "Loss:  [2.798e-08]\n",
      "[[0.5]]\n",
      "[[0.9]]\n",
      "[[1.]]\n",
      "[[2.]]\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "def train(epochs, size=100):\n",
    "    for i in range(epochs):\n",
    "        tmp = 0.0\n",
    "        for x in range(size):\n",
    "            y1 = randint(0,1)\n",
    "            y2 = randint(0,1)\n",
    "            tmp += back_prop(forward_prop(np.array([y1,y2])), np.array([y1+y2]))[0]\n",
    "        print(\"Loss: \", tmp/size)\n",
    "\n",
    "initialize(do_print=False)\n",
    "train(20, 100)\n",
    "print(forward_prop(np.array([0.2,0.3])))\n",
    "print(forward_prop(np.array([0.7,0.2])))\n",
    "print(forward_prop(np.array([1,0])))\n",
    "print(forward_prop(np.array([1,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  [0.129]\n",
      "Loss:  [0.07]\n",
      "Loss:  [0.072]\n",
      "Loss:  [0.065]\n",
      "Loss:  [0.153]\n",
      "Loss:  [0.134]\n",
      "Loss:  [0.069]\n",
      "Loss:  [0.068]\n",
      "Loss:  [0.011]\n",
      "Loss:  [0.001]\n",
      "Loss:  [0.]\n",
      "Loss:  [7.468e-05]\n",
      "Loss:  [3.411e-05]\n",
      "Loss:  [1.103e-05]\n",
      "Loss:  [3.904e-06]\n",
      "Loss:  [1.524e-06]\n",
      "Loss:  [5.7e-07]\n",
      "Loss:  [2.179e-07]\n",
      "Loss:  [7.967e-08]\n",
      "Loss:  [2.893e-08]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n",
      "[[1.437e-05]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11d899450>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [\n",
    "    [0,1],\n",
    "    [0,0],\n",
    "    [1,0],\n",
    "    [1,1]\n",
    "]\n",
    "\n",
    "y = [1,0,1,0]\n",
    "\n",
    "initialize(-1, 1, do_print=False)\n",
    "\n",
    "def train(epochs, size=100):\n",
    "    l = []\n",
    "    for i in range(epochs):\n",
    "        tmp = 0.0\n",
    "        for x in range(size):\n",
    "            y1 = randint(0,3)\n",
    "            tmp += back_prop(forward_prop(np.array(X[y1])), np.array(y[y1]))[0]\n",
    "        l.append(tmp/size)\n",
    "        print(\"Loss: \", tmp/size)\n",
    "    return np.array(l).flatten()\n",
    "\n",
    "loss_over_time =  train(20,1000)\n",
    "\n",
    "print(forward_prop(np.array([1,0])))\n",
    "print(forward_prop(np.array([0,1])))\n",
    "print(forward_prop(np.array([0,0])))\n",
    "print(forward_prop(np.array([1,1])))\n",
    "\n",
    "plt.plot(loss_over_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Backpropagation Implementation\n",
    "Exmaple: Learning XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Loss: [0.103]\n",
      "[Epoch 1] Loss: [0.043]\n",
      "[Epoch 2] Loss: [0.05]\n",
      "[Epoch 3] Loss: [0.059]\n",
      "[Epoch 4] Loss: [0.059]\n",
      "[Epoch 5] Loss: [0.019]\n",
      "[Epoch 6] Loss: [0.019]\n",
      "[Epoch 7] Loss: [0.]\n",
      "[Epoch 8] Loss: [2.114e-06]\n",
      "[[9.999e-01]\n",
      " [1.000e+00]\n",
      " [2.743e-04]\n",
      " [4.151e-04]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "\n",
    "\n",
    "def backprop_entry(X, y, print_loss=False):\n",
    "    global a, z, w, b, n_weights, n_bias\n",
    "    n_weights, n_bias = [], []\n",
    "    \n",
    "    backprop_rec(0, X, y)\n",
    "    \n",
    "    # Update Weights\n",
    "    w = list(reversed(n_weights))\n",
    "    b = list(reversed(n_bias))\n",
    "    return 0.5*(y - X)**2  # Return Loss\n",
    "\n",
    "\n",
    "def backprop_rec(i, X, y):\n",
    "    global a, z, w, b, n_weights, n_bias\n",
    "\n",
    "    # Base Case\n",
    "    if i+1 > len(w): return (X - y).reshape(1,-1).T\n",
    "    \n",
    "    g = backprop_rec(i+1, X, y) * relu(z[i], True)  # Get Next Layer Derivative\n",
    "    \n",
    "    # Derivative with respect to weight [1xn]  \n",
    "    if i-1 < 0: w_der = y.reshape(1,-1).T  # Input Matrix\n",
    "    else: w_der = a[i-1].reshape(1,-1).T  # Previous Layer Activation\n",
    "\n",
    "    # Save change in weights\n",
    "    n_weights.append(w[i] - learning_rate * (w_der @ g))\n",
    "    n_bias.append(b[i] - learning_rate * g)\n",
    "    \n",
    "    return g @ w[i].T \n",
    "\n",
    "def train_rec(epochs, size=100, threshold=0.0001):\n",
    "    l = []\n",
    "    for i in range(epochs):\n",
    "        sum_loss = 0.0\n",
    "        for x in range(size):\n",
    "            y1 = randint(0,3)\n",
    "            \n",
    "            sum_loss += backprop_entry(forward_prop(np.array(X[y1])), np.array(y[y1]))[0]\n",
    "        l.append(sum_loss/size)\n",
    "        print(f'[Epoch {i}] Loss: {l[-1]}')\n",
    "        if l[-1] < threshold or l[-1] != l[-1]: break\n",
    "    return np.array(l).flatten()\n",
    "\n",
    "# Reinitialize Weights & Bias\n",
    "initialize(-1, 1, do_print=False)\n",
    "\n",
    "loss_over_time = train_rec(200,1000)\n",
    "\n",
    "\n",
    "print(forward_prop(np.array([[1,0], \n",
    "                             [0,1], \n",
    "                             [1,1], \n",
    "                             [0,0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "name": "Minimal Backprop.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
